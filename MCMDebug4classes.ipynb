{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mid Circuit Measurement 4 classes Debug",
   "id": "9546069717713df4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:05:02.207052Z",
     "start_time": "2024-09-23T15:04:59.732604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from data_utils import mnist_preparation \n",
    "from evaluationUtils import calculate_mcm_accuracy\n",
    "from tqdm import tqdm\n",
    "import matplotlib as plt\n",
    "from OriginalModel import FullQuantumModel, QuantumCircuit\n",
    "from mcmModel import MCMQuantumModel, MCMCircuit\n",
    "from pennylane import Device\n",
    "from pennylane.measurements import StateMP\n",
    "from torch.nn import Module, ParameterDict\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from typing import Optional, Dict, List, Any\n",
    "from torch.utils.data import DataLoader, dataloader\n",
    "from time import time\n",
    "import math\n",
    "from pennylane.measurements import MidMeasureMP\n",
    "torch.manual_seed(1234)"
   ],
   "id": "e04b727317160b8f",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:44:58.783514Z",
     "start_time": "2024-09-16T15:44:56.571211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = [0,1,2,3]\n",
    "# Download MNIST and prepare transforms\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([\n",
    "                                transforms.Resize((16, 16)),  # Resize to 16x16\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))  # Normalize\n",
    "                             ]))\n",
    "#train/vali/test 70/15/15 split, see data_utils.py for further details\n",
    "train_dataloader, validation_dataloader, test_dataloader = mnist_preparation(dataset=mnist, labels = labels, train_test_ratio=0.7,batch_size=64, vali_test_ratio=0.5)\n",
    "\n",
    "print(\"Images in the training set: \", len(train_dataloader.dataset), \"\\n Images in the validation set: \", len(validation_dataloader.dataset), \"\\n Images in the test set: \", len(test_dataloader.dataset))"
   ],
   "id": "2445714fe5540bf6",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline Model",
   "id": "d68a76425e2cd726"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T15:33:43.287344Z",
     "start_time": "2024-09-12T15:33:42.432079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline = FullQuantumModel(qubits=8, layers=8, num_classes=4)\n",
    "baseline.trainable_parameters()\n",
    "baseline.draw(style='sketch')"
   ],
   "id": "59313bb299be1df7",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T15:39:10.309921Z",
     "start_time": "2024-09-12T15:33:53.283773Z"
    }
   },
   "cell_type": "code",
   "source": "accuracy_history, loss_history = baseline.fit(dataloader=train_dataloader, learning_rate=0.001, epochs=20, show_plot=True)",
   "id": "3d944b5102032e24",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline Evaluation",
   "id": "59f89cf985cee09f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T15:47:16.851658Z",
     "start_time": "2024-09-12T15:46:14.146256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline.freeze_layers([0,1,2,3,4,5,6,7])\n",
    "baseline.trainable_parameters()\n",
    "\n",
    "#simplified per image test set evaluation\n",
    "result = []\n",
    "for img, label in tqdm(test_dataloader.dataset):\n",
    "    img = img / torch.linalg.norm(img).view(-1, 1) #image normalization\n",
    "    probs = baseline.forward(state=img) #extract probabilities\n",
    "    prediction = torch.argmax(probs, dim=1)\n",
    "    result.append((prediction, label))\n",
    "    \n",
    "def calculate_accuracy(data):\n",
    "    correct = sum([1 for label, prediction in data if label == prediction])\n",
    "    return correct, correct / len(data)\n",
    "\n",
    "test_results = calculate_accuracy(result)\n",
    "\n",
    "print(test_results[0], \"elements have been correctly classified over\", len(test_dataloader.dataset), \"total images with an accuracy of \", test_results[1])"
   ],
   "id": "2e437424328f66e0",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MCM Model 4 classes ",
   "id": "5b4ab8ea3881aceb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:45:06.569478Z",
     "start_time": "2024-09-16T15:45:06.564135Z"
    }
   },
   "cell_type": "code",
   "source": "mcm_model4 = MCMQuantumModel(qubits = 8, layers = 8, ansatz='ansatz_1')",
   "id": "9d5633496035e4e5",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:45:07.910199Z",
     "start_time": "2024-09-16T15:45:06.927653Z"
    }
   },
   "cell_type": "code",
   "source": "mcm_model4.draw(style='sketch', path='mcm_model4class')",
   "id": "25f472de277798f4",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T20:26:27.691057Z",
     "start_time": "2024-09-12T18:51:27.423579Z"
    }
   },
   "cell_type": "code",
   "source": "mcm_accuracy, fm_accuracy, loss_history = mcm_model4.fit(dataloader=train_dataloader, learning_rate=0.001, epochs=50, show_plot=True)",
   "id": "7c17c3a61685b43d",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T20:28:52.168344Z",
     "start_time": "2024-09-12T20:28:52.161853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import pickle\n",
    "#model4_params = mcm_model4.params\n",
    "#with open(\"/Users/jackvittori/Desktop/pesimcm4.pickle\", \"wb\") as file:\n",
    "#    pickle.dump(model4_params, file)"
   ],
   "id": "a3aef2830551782e",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:45:14.636699Z",
     "start_time": "2024-09-16T15:45:14.631319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open(\"/Users/jackvittori/Desktop/pesimcm4.pickle\", \"rb\") as file:\n",
    "    model4_params = pickle.load(file) "
   ],
   "id": "214b590aa4f0e60b",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:45:16.646743Z",
     "start_time": "2024-09-16T15:45:16.642401Z"
    }
   },
   "cell_type": "code",
   "source": "model4_params['layer_1']",
   "id": "54803662f9c8fff6",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:45:17.891001Z",
     "start_time": "2024-09-16T15:45:17.887596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mcm_model4.set_parameters(model4_params)\n",
    "mcm_model4.params['layer_1']"
   ],
   "id": "f25eb485f676277b",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Early Exit with full-evaluation",
   "id": "1c5996dce13e032d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:46:55.209945Z",
     "start_time": "2024-09-16T15:45:26.430801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction_results = {\"early\": [], \"final\": []}\n",
    "for img, target in tqdm(test_dataloader.dataset):\n",
    "    #img normalization\n",
    "    img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "    #probs extraction\n",
    "    mcm_probs, final_probs = mcm_model4.forward(state=img)\n",
    "    #mcm prediction and confidence\n",
    "    mcm_predictions = torch.argmax(mcm_probs, dim=1)\n",
    "    mcm_correct = mcm_predictions == target\n",
    "    early_confidence = mcm_probs[0,mcm_predictions]\n",
    "    prediction_results[\"early\"].append((mcm_correct, early_confidence))\n",
    "    \n",
    "    #fm prediction\n",
    "    final_predictions = torch.argmax(final_probs, dim=1)\n",
    "    final_correct = final_predictions == target\n",
    "    prediction_results[\"final\"].append((final_correct))"
   ],
   "id": "366433779204a11d",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:46:55.213366Z",
     "start_time": "2024-09-16T15:46:55.210934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def post_evaluation_threshold(early_results, final_results, threshold):\n",
    "    results = [] #chosen prediction per image\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    mcm_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    \n",
    "    for i, (early_bool, confidence) in enumerate(early_results):\n",
    "        if confidence.item() > threshold:\n",
    "            results.append(early_bool.item()) #use early prediction\n",
    "            count_1 += 1\n",
    "            if early_bool: \n",
    "                mcm_correct += 1\n",
    "        else:\n",
    "            results.append(final_results[i][0].item()) #use final prediction\n",
    "            count_2 += 1\n",
    "            if final_results[i][0].item():\n",
    "                final_correct += 1\n",
    "            \n",
    "    return results, mcm_correct, count_1, final_correct, count_2"
   ],
   "id": "2b5d06bd81366c6",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:46:55.216591Z",
     "start_time": "2024-09-16T15:46:55.213851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explain_results(results: Dict, threshold: List[float]):\n",
    "    summary_data = {\n",
    "        'Threshold': [],\n",
    "        'Total Accuracy': [],\n",
    "        'Early Classified': [],\n",
    "        'Early Accuracy': [],\n",
    "        'Final Classified': [],\n",
    "        'Final Accuracy': []}\n",
    "    \n",
    "    for t in threshold:\n",
    "        prediction_result, mcm_correct, n_early, final_correct, n_final = post_evaluation_threshold(results['early'], results['final'], t)\n",
    "        tot_accuracy = sum([1 for i in prediction_result if i == True]) / len(prediction_result)\n",
    "        \n",
    "        #avoid division by 0\n",
    "        early_accuracy = mcm_correct / n_early if n_early > 0 else 0\n",
    "        final_accuracy = final_correct / n_final if n_final > 0 else 0\n",
    "\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(tot_accuracy)\n",
    "        summary_data['Early Classified'].append(n_early)\n",
    "        summary_data['Early Accuracy'].append(early_accuracy)\n",
    "        summary_data['Final Classified'].append(n_final)\n",
    "        summary_data['Final Accuracy'].append(final_accuracy)\n",
    "        # print(f\" tot accuracy {tot_accuracy}, average mean, {(n_early*early_accuracy + n_final*final_accuracy)/(n_early + n_final)}\")\n",
    "    \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return df"
   ],
   "id": "5eb5ccb1580e5e08",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:47:36.143210Z",
     "start_time": "2024-09-16T15:47:36.131105Z"
    }
   },
   "cell_type": "code",
   "source": "threshold = [round(x * 0.02 + 0.2, 2) for x in range(31)]",
   "id": "1c115b0ff0585621",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:47:36.858302Z",
     "start_time": "2024-09-16T15:47:36.355840Z"
    }
   },
   "cell_type": "code",
   "source": "explain_results(prediction_results, threshold)",
   "id": "96c5f71715cad54d",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Early Exit without full execution",
   "id": "eb260cd54bdd4a5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:47:53.145852Z",
     "start_time": "2024-09-16T15:47:53.135298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def early_evaluation_utils(params: Dict, state: torch.Tensor = None): \n",
    "    first_pair = [0,1]\n",
    "    measurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(params[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(params[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(params[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "    \n",
    "    for w in first_pair: \n",
    "        measurements.append(qml.measure(wires=w)) #measure first pair of qubits\n",
    "    return measurements\n",
    "\n",
    "def fully_evaluation_utils(params: Dict, state: torch.Tensor = None):\n",
    "    first_pair = [0,1]\n",
    "    second_pair = [2,3]\n",
    "    mcasurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(params[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(params[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(params[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            \n",
    "    for w in first_pair: \n",
    "        mcasurements.append(qml.measure(wires=w)) #measure first pair of qubits\n",
    "\n",
    "    for i in range(4, 8):\n",
    "        for j in range(8):\n",
    "            qml.RX(params[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(params[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(params[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "\n",
    "    for w in second_pair:\n",
    "        mcasurements.append(qml.measure(wires=w))\n",
    "\n",
    "    return mcasurements"
   ],
   "id": "54e231a4281b612e",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:47:54.739361Z",
     "start_time": "2024-09-16T15:47:54.734744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dev = qml.device(\"default.qubit\", wires=8)\n",
    "@qml.qnode(dev)  \n",
    "def early_evaluation_ansatz(params: Dict, state: torch.Tensor = None):\n",
    "    early_measurement = early_evaluation_utils(params=params, state=state)\n",
    "    return qml.probs(op=early_measurement)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def fully_evaluation_ansatz(params: Dict, state: torch.Tensor = None):\n",
    "    measurements = fully_evaluation_utils(params=params, state=state)\n",
    "    mid_measurement = measurements[:2]\n",
    "    final_measurement = measurements[2:]\n",
    "    return qml.probs(op=mid_measurement), qml.probs(op=final_measurement)"
   ],
   "id": "b0bf064eed182e3",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:47:56.537406Z",
     "start_time": "2024-09-16T15:47:56.535243Z"
    }
   },
   "cell_type": "code",
   "source": "parameters4classes = mcm_model4.params",
   "id": "682e6a943252978",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:04:52.042166Z",
     "start_time": "2024-09-23T15:04:51.963073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "early_evaluate_model, ax1 = qml.draw_mpl(early_evaluation_ansatz)(parameters4classes)\n",
    "\n",
    "early_evaluate_model.savefig('early_evaluate_model.png')"
   ],
   "id": "bbf028fd88842bc",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:06:37.771541Z",
     "start_time": "2024-09-23T15:06:37.730712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_evaluate_model, ax2 = qml.draw_mpl(fully_evaluation_ansatz)(parameters4classes)\n",
    "\n",
    "final_evaluate_model.savefig('final_evaluate_model.png')"
   ],
   "id": "2bfb4ecf10aaa9cd",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation Routine Definition",
   "id": "bd1a96b24260147c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:48:06.762522Z",
     "start_time": "2024-09-16T15:48:06.759047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_routine(dataloader: DataLoader, parameters: Dict, threshold: float):\n",
    "    \n",
    "    evaluation_results = []\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    early_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    for img, target in dataloader.dataset:\n",
    "        #img normalization\n",
    "        img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "        \n",
    "        #mid circuit evaluation\n",
    "        early_probs = early_evaluation_ansatz(params=parameters, state=img)\n",
    "        early_prediction = torch.argmax(early_probs, dim=1)\n",
    "        confidence = early_probs[0, early_prediction].item()\n",
    "        if confidence >= threshold:\n",
    "            early_guess = early_prediction == target\n",
    "            evaluation_results.append(early_guess.item())\n",
    "            count_1 += 1\n",
    "            if early_guess: \n",
    "                early_correct += 1\n",
    "            \n",
    "        else: \n",
    "            final_probs = fully_evaluation_ansatz(params=parameters, state=img)\n",
    "            early_full, final_full = final_probs\n",
    "            final_predictions = torch.argmax(final_full, dim=1)\n",
    "            final_guess = final_predictions == target\n",
    "            evaluation_results.append(final_guess.item())\n",
    "            count_2 += 1\n",
    "            if final_guess: \n",
    "                final_correct += 1\n",
    "    total_accuracy = sum([1 for i in evaluation_results if i == True])/len(evaluation_results)\n",
    "    early_accuracy = early_correct/count_1 if count_1 > 0 else 0\n",
    "    final_accuracy = final_correct/count_2 if count_2 > 0 else 0\n",
    "    \n",
    "    return total_accuracy, early_accuracy, count_1, final_accuracy, count_2"
   ],
   "id": "f4fbdfd5d5c1463d",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:48:07.465298Z",
     "start_time": "2024-09-16T15:48:07.462437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explain_evaluation(dataloader: DataLoader, parameters: Dict, threshold: List[float]):\n",
    "    summary_data = {\n",
    "    'Threshold': [],\n",
    "    'Total Accuracy': [],\n",
    "    'Early Classified': [],\n",
    "    'Early Accuracy': [],\n",
    "    'Final Classified': [],\n",
    "    'Final Accuracy': []}\n",
    "    \n",
    "    for t in tqdm(threshold):\n",
    "        tot_acc, early_acc, early_count, final_acc, final_count = evaluation_routine(dataloader, parameters, t)\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(tot_acc)\n",
    "        summary_data['Early Classified'].append(early_count)\n",
    "        summary_data['Early Accuracy'].append(early_acc)\n",
    "        summary_data['Final Classified'].append(final_count)\n",
    "        summary_data['Final Accuracy'].append(final_acc)\n",
    "        \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return df"
   ],
   "id": "9482d7c422ad7402",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T16:02:05.536452Z",
     "start_time": "2024-09-16T15:49:15.453175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#threshold = [round(x * 0.02 + 0.3, 2) for x in range(31)]\n",
    "threshold = [0.2, 0.3, 0.35,0.36, 0.38, 0.40, 0.45, 0.5]\n",
    "explain_evaluation(test_dataloader, parameters4classes, threshold)"
   ],
   "id": "b082f095159d233c",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "b9a26a0f3112da10",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
