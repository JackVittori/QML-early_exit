{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mid Circuit Measurement 2 classes Debug\n",
   "id": "84e1195c000cb272"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:47:57.498157Z",
     "start_time": "2024-09-12T12:47:53.895103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from data_utils import mnist_preparation \n",
    "from evaluationUtils import calculate_mcm_accuracy\n",
    "from tqdm import tqdm\n",
    "import matplotlib as plt\n",
    "from OriginalModel import FullQuantumModel, QuantumCircuit\n",
    "from mcmModel import MCMQuantumModel, MCMCircuit\n",
    "from pennylane import Device\n",
    "from pennylane.measurements import StateMP\n",
    "from torch.nn import Module, ParameterDict\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from typing import Optional, Dict, List, Any\n",
    "from torch.utils.data import DataLoader, dataloader\n",
    "from time import time\n",
    "import math\n",
    "from pennylane.measurements import MidMeasureMP\n",
    "torch.manual_seed(1234)"
   ],
   "id": "a6758fcf8aa70e09",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First of all let's import data with train/validation/test split of 70/15/15. ",
   "id": "e427f91036285d4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:47:59.580916Z",
     "start_time": "2024-09-12T12:47:57.499024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = [0,1]\n",
    "# Download MNIST and prepare transforms\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([\n",
    "                                transforms.Resize((16, 16)),  # Resize to 16x16\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))  # Normalize\n",
    "                             ]))\n",
    "#train/vali/test 70/15/15 split, see data_utils.py for further details\n",
    "train_dataloader, validation_dataloader, test_dataloader = mnist_preparation(dataset=mnist, labels = labels, train_test_ratio=0.7,batch_size=64, vali_test_ratio=0.5)\n",
    "\n",
    "print(\"Images in the training set: \", len(train_dataloader.dataset), \"\\n Images in the validation set: \", len(validation_dataloader.dataset), \"\\n Images in the test set: \", len(test_dataloader.dataset))"
   ],
   "id": "f9868cfb8aec7f4",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Baseline Model\n",
    "\n",
    "See [OriginalModel.py](https://github.com/JackVittori/QML-early_exit/blob/main/OriginalModel.py) for further details. Highlights are hereafter reported: \n",
    "\n",
    "- a layer is composed by RX, RY, RZ rotations on each qubit and CNOT gates to create entanglement (24 params x layer); \n",
    "- the quantum circuit return is the quantum state;\n",
    "- probability is extracted from the first qubit using the following Python code (the first 128 states are associated to measuring 0 on the first qubit, the others to measuring 1):   \n",
    "```python \n",
    "if self.num_classes == 2:\n",
    "    state_vector = self.quantum_layer(state=state, num_layers_to_execute=num_layers_to_execute)\n",
    "    probabilities = torch.sum(torch.abs(state_vector[:, :2 ** (self.quantum_layer.num_qubits - 1)]) ** 2, dim=1)\n",
    "    return probabilities.type(torch.float32)\n",
    "```\n",
    "- train with ```python torch.nn.BCELoss()```"
   ],
   "id": "6830ff5b1820f339"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T14:09:36.356534Z",
     "start_time": "2024-09-11T14:09:35.356549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline = FullQuantumModel(qubits=8, layers=8, num_classes=2)\n",
    "baseline.trainable_parameters()\n",
    "baseline.draw(style='sketch')"
   ],
   "id": "c11dcf001e830b6e",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T12:15:37.958096Z",
     "start_time": "2024-09-11T12:15:37.956278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#We could freeze a layer if we want with the following method of the class in OriginalModel.py\n",
    "baseline.freeze_layers([0,1])\n",
    "baseline.trainable_layers()\n",
    "baseline.trainable_parameters()"
   ],
   "id": "8ed51020d1491bd2",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T12:15:37.960628Z",
     "start_time": "2024-09-11T12:15:37.959024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We can also unfreeze them\n",
    "baseline.unfreeze_layers([0,1])\n",
    "baseline.trainable_layers()\n",
    "baseline.trainable_parameters()"
   ],
   "id": "b56e83f53e25ff5f",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "accuracy_history, loss_history = baseline.fit(dataloader=train_dataloader, learning_rate=0.001, epochs=20, show_plot=True)",
   "id": "168e08394f9c1cd4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Baseline evaluation",
   "id": "cd78f71e209763a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T12:17:30.051649Z",
     "start_time": "2024-09-11T12:16:59.401190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline.freeze_layers([0,1,2,3,4,5,6,7])\n",
    "baseline.trainable_parameters()\n",
    "\n",
    "#simplified per image test set evaluation\n",
    "result = []\n",
    "for img, label in tqdm(test_dataloader.dataset):\n",
    "    img = img / torch.linalg.norm(img).view(-1, 1) #image normalization\n",
    "    pred = torch.round(baseline.forward(state=img)) #extract pred\n",
    "    result.append((pred, label))\n",
    "    \n",
    "def calculate_accuracy(data):\n",
    "    correct = sum([1 for label, prediction in data if label == prediction])\n",
    "    return correct, correct / len(data)\n",
    "\n",
    "test_results = calculate_accuracy(result)\n",
    "\n",
    "print(test_results[0], \"elements have been correctly classified over\", len(test_dataloader.dataset), \"total images with an accuracy of \", test_results[1])"
   ],
   "id": "59627866150fb99a",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MCM model\n",
    "\n"
   ],
   "id": "25a2e7c125005d6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:48:10.632595Z",
     "start_time": "2024-09-12T12:48:10.628903Z"
    }
   },
   "cell_type": "code",
   "source": "mcm_model = MCMQuantumModel(qubits=8, layers=8, ansatz='2-class')",
   "id": "b3687f39b060e92e",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:48:11.886649Z",
     "start_time": "2024-09-12T12:48:10.847859Z"
    }
   },
   "cell_type": "code",
   "source": "mcm_model.draw(style='sketch', path=\"mcm_model.png\")",
   "id": "79cb8de5ca675a6d",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:55:19.352739Z",
     "start_time": "2024-09-12T12:48:16.555412Z"
    }
   },
   "cell_type": "code",
   "source": "mcm_accuracy, fm_accuracy, loss_history = mcm_model.fit(dataloader=train_dataloader, learning_rate=0.001, epochs=20, show_plot=True)",
   "id": "b73036fd04cc20f0",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Early Exit with full-evaluation\n",
    "Let's first try to execute every time the whole circuit for each image as it was trained, post-selecting the exit varying the threshold.  "
   ],
   "id": "e4efe00bd0d8624e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:57:38.101764Z",
     "start_time": "2024-09-12T12:56:58.016618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction_results = {\"early\": [], \"final\": []}\n",
    "for img, target in tqdm(test_dataloader.dataset):\n",
    "    #img normalization\n",
    "    img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "    #probs extraction\n",
    "    mcm_probs, final_probs = mcm_model.forward(state=img)\n",
    "    #mcm prediction and confidence\n",
    "    mcm_predictions = torch.argmax(mcm_probs, dim=1)\n",
    "    mcm_correct = mcm_predictions == target\n",
    "    early_confidence = mcm_probs[0,mcm_predictions]\n",
    "    prediction_results[\"early\"].append((mcm_correct, early_confidence))\n",
    "    \n",
    "    #fm prediction\n",
    "    final_predictions = torch.argmax(final_probs, dim=1)\n",
    "    final_correct = final_predictions == target\n",
    "    prediction_results[\"final\"].append((final_correct))"
   ],
   "id": "66291243afd59dd5",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`results['early']` will contain a list of tensors containing: \n",
    "- a boolean containing a True if the prediction was correct; \n",
    "- the confidence measure associated to measure 0 if 0 was predicted, associated to 1 if 1 was predicted\n",
    "\n",
    "\n",
    "`results['final']` is a list of booleans containing True if the prediction was correct and Falso if it was uncorrect. "
   ],
   "id": "cb84bcd9f16b22b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's try to post select the exit varying the threshold, taking early prediction when the probability associated to the early prediciton is above a threshold and the final prediction when the condition is not satisfied: ",
   "id": "1c3cb4c2feefc7bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:57:42.920286Z",
     "start_time": "2024-09-12T12:57:42.914501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def post_evaluation_threshold(early_results, final_results, threshold):\n",
    "    results = [] #chosen prediction per image\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    mcm_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    \n",
    "    for i, (early_bool, confidence) in enumerate(early_results):\n",
    "        if confidence.item() > threshold:\n",
    "            results.append(early_bool.item()) #use early prediction\n",
    "            count_1 += 1\n",
    "            if early_bool: \n",
    "                mcm_correct += 1\n",
    "        else:\n",
    "            results.append(final_results[i][0].item()) #use final prediction\n",
    "            count_2 += 1\n",
    "            if final_results[i][0].item():\n",
    "                final_correct += 1\n",
    "            \n",
    "    return results, mcm_correct, count_1, final_correct, count_2"
   ],
   "id": "a965ae15778d3e2b",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:57:44.484218Z",
     "start_time": "2024-09-12T12:57:44.480841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explain_results(results: Dict, threshold: List[float]):\n",
    "    summary_data = {\n",
    "        'Threshold': [],\n",
    "        'Total Accuracy': [],\n",
    "        'Early Classified': [],\n",
    "        'Early Accuracy': [],\n",
    "        'Final Classified': [],\n",
    "        'Final Accuracy': []}\n",
    "    \n",
    "    for t in threshold:\n",
    "        prediction_result, mcm_correct, n_early, final_correct, n_final = post_evaluation_threshold(results['early'], results['final'], t)\n",
    "\n",
    "        tot_accuracy = sum([1 for i in prediction_result if i == True]) / len(prediction_result)\n",
    "        \n",
    "        #avoid division by 0\n",
    "        early_accuracy = mcm_correct / n_early if n_early > 0 else 0\n",
    "        final_accuracy = final_correct / n_final if n_final > 0 else 0\n",
    "\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(tot_accuracy)\n",
    "        summary_data['Early Classified'].append(n_early)\n",
    "        summary_data['Early Accuracy'].append(early_accuracy)\n",
    "        summary_data['Final Classified'].append(n_final)\n",
    "        summary_data['Final Accuracy'].append(final_accuracy)\n",
    "        # print(f\" tot accuracy {tot_accuracy}, average mean, {(n_early*early_accuracy + n_final*final_accuracy)/(n_early + n_final)}\")\n",
    "    \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return df"
   ],
   "id": "9077abec2fb9ad4a",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:57:46.562608Z",
     "start_time": "2024-09-12T12:57:46.560425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#threshold definition\n",
    "threshold = [round(x * 0.02 + 0.3, 2) for x in range(31)]"
   ],
   "id": "fd997b4cc2fbdc9e",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:57:48.574569Z",
     "start_time": "2024-09-12T12:57:48.473473Z"
    }
   },
   "cell_type": "code",
   "source": "explain_results(prediction_results, threshold)",
   "id": "1495edb3207d9ca2",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Early Exits without fully execution\n",
    "\n",
    "We need to define a routine such that: \n",
    "1. take an image\n",
    "2. execute the circuit up to the early exit \n",
    "3. extract prediction and confidence \n",
    "4. two possible scenarios: \n",
    "    - confidence > threshold --> take the mid circuit prediction\n",
    "    - confidence > threshold --> run the whole circuit and take the final prediction \n",
    "5. repeat step 1,2,3,4 over the whole vali/test dataset"
   ],
   "id": "fc2dca14bcf4e220"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:58:28.433526Z",
     "start_time": "2024-09-12T12:58:28.426407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def early_evaluation_utils(params: Dict, state: torch.Tensor = None): \n",
    "    measurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(params[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(params[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(params[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "    measurements.append(qml.measure(wires=0)) #measure first qubit\n",
    "    return measurements\n",
    "\n",
    "def fully_evaluation_utils(params: Dict, state: torch.Tensor = None):\n",
    "    mcasurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(params[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(params[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(params[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "\n",
    "    mcasurements.append(qml.measure(wires=0)) #measure first qubit\n",
    "\n",
    "    for i in range(4, 8):\n",
    "        for j in range(8):\n",
    "            qml.RX(params[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(params[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(params[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "\n",
    "    mcasurements.append(qml.measure(wires=1)) #measure second qubit\n",
    "\n",
    "    return mcasurements"
   ],
   "id": "7dd414e7803d39c5",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:40:12.761178Z",
     "start_time": "2024-09-12T13:40:12.758115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#device definition\n",
    "dev = qml.device(\"default.qubit\", wires=8)\n",
    "@qml.qnode(dev)  \n",
    "def early_evaluation_ansatz(params: Dict, state: torch.Tensor = None):\n",
    "    early_measurement = early_evaluation_utils(params=params, state=state)\n",
    "    return qml.probs(op=early_measurement)\n",
    "\n",
    "#dev2 = qml.device(\"default.qubit\", wires=8)\n",
    "@qml.qnode(dev)\n",
    "def fully_evaluation_ansatz(params: Dict, state: torch.Tensor = None):\n",
    "    measurements = fully_evaluation_utils(params=params, state=state)\n",
    "    mid_measurement,final_measurement = measurements \n",
    "    return qml.probs(op=mid_measurement), qml.probs(op=final_measurement)"
   ],
   "id": "373568e9d4096b42",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can extract the trained parameters and plot the circuits that will be used for the evaluation: ",
   "id": "3e29a18588db71fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:40:13.931293Z",
     "start_time": "2024-09-12T13:40:13.929764Z"
    }
   },
   "cell_type": "code",
   "source": "binary_parameters = mcm_model.params",
   "id": "a243fb2de75ed785",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:40:14.826838Z",
     "start_time": "2024-09-12T13:40:14.488516Z"
    }
   },
   "cell_type": "code",
   "source": "early_evaluate_model, ax1 = qml.draw_mpl(early_evaluation_ansatz)(binary_parameters)",
   "id": "f8fb9a46afd30ab5",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:40:16.250255Z",
     "start_time": "2024-09-12T13:40:15.589620Z"
    }
   },
   "cell_type": "code",
   "source": "final_evaluate_model, ax2 = qml.draw_mpl(fully_evaluation_ansatz)(binary_parameters)",
   "id": "2e2efd95e8749643",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluation routine definition\n",
    "Let's define the routine that will be used for the evaluation."
   ],
   "id": "e590957b3b234919"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T15:05:29.483538Z",
     "start_time": "2024-09-12T15:05:29.480215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_routine(dataloader: DataLoader, parameters: Dict, threshold: float):\n",
    "    \n",
    "    evaluation_results = []\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    early_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    for img, target in dataloader.dataset:\n",
    "        #img normalization\n",
    "        img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "        \n",
    "        #mid circuit evaluation\n",
    "        early_probs = early_evaluation_ansatz(params=parameters, state=img)\n",
    "        early_prediction = torch.argmax(early_probs, dim=1)\n",
    "        confidence = early_probs[0, early_prediction].item()\n",
    "        if confidence >= threshold:\n",
    "            early_guess = early_prediction == target\n",
    "            evaluation_results.append(early_guess.item())\n",
    "            count_1 += 1\n",
    "            if early_guess: \n",
    "                early_correct += 1\n",
    "            \n",
    "        else: \n",
    "            final_probs = fully_evaluation_ansatz(params=parameters, state=img)\n",
    "            early_full, final_full = final_probs\n",
    "            final_predictions = torch.argmax(final_full, dim=1)\n",
    "            final_guess = final_predictions == target\n",
    "            evaluation_results.append(final_guess.item())\n",
    "            count_2 += 1\n",
    "            if final_guess: \n",
    "                final_correct += 1\n",
    "    total_accuracy = sum([1 for i in evaluation_results if i == True])/len(evaluation_results)\n",
    "    early_accuracy = early_correct/count_1 if count_1 > 0 else 0\n",
    "    final_accuracy = final_correct/count_2 if count_2 > 0 else 0\n",
    "    \n",
    "    return total_accuracy, early_accuracy, count_1, final_accuracy, count_2"
   ],
   "id": "6b3b570432122cbb",
   "execution_count": 109,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T15:05:32.938536Z",
     "start_time": "2024-09-12T15:05:32.936025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explain_evaluation(dataloader: DataLoader, parameters: Dict, threshold: List[float]):\n",
    "    summary_data = {\n",
    "    'Threshold': [],\n",
    "    'Total Accuracy': [],\n",
    "    'Early Classified': [],\n",
    "    'Early Accuracy': [],\n",
    "    'Final Classified': [],\n",
    "    'Final Accuracy': []}\n",
    "    \n",
    "    for t in tqdm(threshold):\n",
    "        tot_acc, early_acc, early_count, final_acc, final_count = evaluation_routine(dataloader, parameters, t)\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(tot_acc)\n",
    "        summary_data['Early Classified'].append(early_count)\n",
    "        summary_data['Early Accuracy'].append(early_acc)\n",
    "        summary_data['Final Classified'].append(final_count)\n",
    "        summary_data['Final Accuracy'].append(final_acc)\n",
    "        \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return df"
   ],
   "id": "7a9cb7134b8a634c",
   "execution_count": 110,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T15:22:28.475068Z",
     "start_time": "2024-09-12T15:05:33.477536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "threshold = [round(x * 0.02 + 0.3, 2) for x in range(31)]\n",
    "explain_evaluation(test_dataloader, binary_parameters, threshold)"
   ],
   "id": "1e9c18dd1297db3e",
   "execution_count": 111,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
