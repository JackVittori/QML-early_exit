{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Simple QNN for MNIST classification"
   ],
   "metadata": {
    "id": "mqUAmvcx72pp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ],
   "metadata": {
    "id": "UEzpzd5m745s",
    "ExecuteTime": {
     "end_time": "2024-09-26T16:48:14.022019Z",
     "start_time": "2024-09-26T16:48:12.398481Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of PennyLane circuit"
   ],
   "metadata": {
    "id": "H29-Z9qZ-2MM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "NUM_QUBITS = 8\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "# get the device\n",
    "dev = qml.device(\"default.mixed\", wires=NUM_QUBITS)\n",
    "\n",
    "# circuit using the strongly entangling layer ansatz\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def circuit_block(params, state=None):\n",
    "\n",
    "    # Load the initial state if provided\n",
    "    if state is not None: qml.QubitStateVector(state, wires=range(NUM_QUBITS))\n",
    "\n",
    "    # Real quantum encoding (using amplitude encoding)\n",
    "    #if state is not None: qml.AmplitudeEmbedding(features=state, wires=range(NUM_QUBITS))\n",
    "\n",
    "    #qml.StronglyEntanglingLayers(params, wires=range(NUM_QUBITS), ranges = [1]*params.shape[0])\n",
    "\n",
    "    # Quantum circuit\n",
    "    for i in range(NUM_LAYERS):\n",
    "\n",
    "      # Rotation layer\n",
    "      for j in range(NUM_QUBITS):\n",
    "          qml.RX(params[i, j, 0], wires=j)\n",
    "          qml.RY(params[i, j, 1], wires=j)\n",
    "          qml.RZ(params[i, j, 2], wires=j)\n",
    "\n",
    "      # Entangling layer\n",
    "      for j in range(NUM_QUBITS):\n",
    "          qml.CNOT(wires=[j, (j + 1) % NUM_QUBITS])\n",
    "\n",
    "\n",
    "    # Return the state vector\n",
    "    return qml.state()\n",
    "\n",
    "  # define general circuit\n",
    "def circuit(params, state):\n",
    "\n",
    "    # apply first small block\n",
    "    state = circuit_block(params, state)\n",
    "    print(state)\n",
    "\n",
    "    # return probability of measuring |0> in the first qubit\n",
    "    return measure(state)\n",
    "\n",
    "# define function that outputs the probability of mesuring |0> in the first qubit\n",
    "def measure(state):\n",
    "\n",
    "    # compute the probability of measuring |0> in the first qubit\n",
    "    prob = torch.sum(torch.abs(state[:,:2**(NUM_QUBITS-1)])**2, dim = 1)\n",
    "\n",
    "    # cast to float32\n",
    "    prob = prob.type(torch.float32)\n",
    "\n",
    "    return prob"
   ],
   "metadata": {
    "id": "YoGnSETn75tF",
    "ExecuteTime": {
     "end_time": "2024-09-26T16:50:24.390575Z",
     "start_time": "2024-09-26T16:50:24.386630Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T16:52:46.166012Z",
     "start_time": "2024-09-26T16:52:46.153837Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "parameters = Variable(torch.normal( mean=0. , std=0.1, size=(NUM_LAYERS, NUM_QUBITS, 3)), requires_grad=True)\n",
    "\n",
    "qml.drawer.use_style(\"black_white\")\n",
    "fig, ax = qml.draw_mpl(circuit_block)(parameters)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "oKeW6VubYChK",
    "outputId": "699466d0-240a-4040-c5b3-c24ddfd3207a",
    "ExecuteTime": {
     "end_time": "2024-09-26T16:48:17.644995Z",
     "start_time": "2024-09-26T16:48:17.391156Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of a full training"
   ],
   "metadata": {
    "id": "-JgFx5lZ-6wD"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RDP7-7Vr7xCY",
    "ExecuteTime": {
     "end_time": "2024-05-07T18:01:01.444998Z",
     "start_time": "2024-05-07T18:01:01.440549Z"
    }
   },
   "source": [
    "def run_exp(learning_rate, num_layers, batch_size, num_epochs, num_qubits, dataloader, loss_fn):\n",
    "\n",
    "    loss_history = []\n",
    "\n",
    "    # initialize parameters randomly\n",
    "    params = torch.randn((num_layers, num_qubits, 3), requires_grad=True)\n",
    "    # define the optimizer\n",
    "    optimizer = torch.optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "    avg_time_per_epoch = 0\n",
    "\n",
    "    # training loop for classification\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        t0 = time()\n",
    "\n",
    "        # Initialize tqdm progress bar with description showing the current epoch\n",
    "        with tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\") as tqdm_epoch:\n",
    "            for _, (data, labels) in tqdm_epoch:\n",
    "\n",
    "                # normalize\n",
    "                data = data / torch.linalg.norm(data, dim=1).view(-1, 1)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward pass\n",
    "                output = circuit(params, data)\n",
    "\n",
    "                # compute the loss\n",
    "                loss = loss_fn(output, labels)\n",
    "\n",
    "                # backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # update the parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                # Optionally, update tqdm bar with batch loss\n",
    "                tqdm_epoch.set_postfix(loss=loss.item(), accuracy=torch.sum((output > 0.5) == labels).item() / batch_size)\n",
    "\n",
    "        avg_time_per_epoch += time()-t0\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        # print the time\n",
    "        print(\"Time per epoch: \", time()-t0)\n",
    "\n",
    "        # print the loss\n",
    "        print(\"Epoch: \", epoch, \"Loss: \", loss.item())\n",
    "\n",
    "        # print the accuracy\n",
    "        print(\"Accuracy: \", torch.sum((output > 0.5) == labels).item()/batch_size)\n",
    "\n",
    "        print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    return avg_time_per_epoch/NUM_EPOCHS, loss_history"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download MNIST and downsample"
   ],
   "metadata": {
    "id": "kPC7TvSmAXzG"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T18:01:03.004277Z",
     "start_time": "2024-05-07T18:01:02.338021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Download MNIST and prepare transforms\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                transforms.Resize((16, 16)),  # Resize to 16x16\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))  # Normalize\n",
    "                             ]))"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T18:01:05.783988Z",
     "start_time": "2024-05-07T18:01:03.005346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter for zeros and ones\n",
    "data = []\n",
    "targets = []\n",
    "for image, label in mnist_train:\n",
    "    if label in [0, 1]:\n",
    "        data.append(image.squeeze())\n",
    "        targets.append(label)\n",
    "\n",
    "data = torch.stack(data)\n",
    "targets = torch.tensor(targets)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T18:01:05.787644Z",
     "start_time": "2024-05-07T18:01:05.784538Z"
    }
   },
   "cell_type": "code",
   "source": "targets.shape",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Select 1024 zeros and 1024 ones for speed\n",
    "zeros_indices = (targets == 0)\n",
    "ones_indices = (targets == 1)\n",
    "\n",
    "zeros = data[zeros_indices]\n",
    "ones = data[ones_indices]\n",
    "\n",
    "# take a subsample of the dataset for simplicity\n",
    "zeros = zeros[:1024]\n",
    "ones = ones[:1024]"
   ],
   "metadata": {
    "id": "EjtVH6Vu_DO1",
    "ExecuteTime": {
     "end_time": "2024-05-07T18:01:05.797755Z",
     "start_time": "2024-05-07T18:01:05.789654Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalize images between 0 and 1"
   ],
   "metadata": {
    "id": "7R0P6JVuNpcs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "zeros_max = torch.max(zeros.reshape(-1, 16*16), dim = 1)\n",
    "zeros_min = torch.min(zeros.reshape(-1, 16*16), dim = 1)\n",
    "ones_max = torch.max(ones.reshape(-1, 16*16), dim = 1)\n",
    "ones_min = torch.min(ones.reshape(-1, 16*16), dim = 1)\n",
    "\n",
    "def normalize(imgs):\n",
    "  maxes, _ = torch.max(imgs.reshape(-1, 16*16), dim = 1)\n",
    "  mins, _ = torch.min(imgs.reshape(-1, 16*16), dim = 1)\n",
    "\n",
    "  mins = mins.unsqueeze(1).unsqueeze(2)\n",
    "  maxes = maxes.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "  return (imgs-mins)/(maxes-mins)\n",
    "\n",
    "zeros = normalize(zeros)\n",
    "ones = normalize(ones)"
   ],
   "metadata": {
    "id": "Vah2MomIH_O-",
    "ExecuteTime": {
     "end_time": "2024-05-07T18:01:05.805432Z",
     "start_time": "2024-05-07T18:01:05.799213Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print a sample for sanity check"
   ],
   "metadata": {
    "id": "zvMQEVVZBxhx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Select a random sample index\n",
    "zero_idx = np.random.randint(0, zeros.shape[0])\n",
    "one_idx = np.random.randint(0, ones.shape[0])\n",
    "\n",
    "# Extract the images\n",
    "sample_zero = zeros[zero_idx]\n",
    "sample_one = ones[one_idx]\n",
    "\n",
    "# Plot the images\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "ax1.imshow(sample_zero, cmap='gray')\n",
    "ax1.set_title('Zero')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(sample_one, cmap='gray')\n",
    "ax2.set_title('One')\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "XwFA3djGBWLR",
    "outputId": "c75969c1-2092-4e57-b469-e342ceaee662",
    "ExecuteTime": {
     "end_time": "2024-05-07T18:01:05.855988Z",
     "start_time": "2024-05-07T18:01:05.806186Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define loss and create dataset"
   ],
   "metadata": {
    "id": "7psbmwJqNukk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# define the cost function\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# assert images have min 0 and max 1 within an error of 1e-5\n",
    "assert torch.allclose(zeros.min(), torch.tensor(0., dtype = torch.float32), atol=1e-5)\n",
    "assert torch.allclose(zeros.max(), torch.tensor(1., dtype = torch.float32), atol=1e-5)\n",
    "assert torch.allclose(ones.min(), torch.tensor(0., dtype = torch.float32), atol=1e-5)\n",
    "assert torch.allclose(ones.max(), torch.tensor(1., dtype = torch.float32), atol=1e-5)\n",
    "\n",
    "# concatenate the two datasets\n",
    "zeros = zeros.flatten(start_dim = 1)\n",
    "ones = ones.flatten(start_dim = 1)\n",
    "dataset = torch.cat((zeros, ones), dim = 0)\n",
    "\n",
    "# add labels\n",
    "labels = torch.cat((torch.zeros((zeros.shape[0], 1)), torch.ones((ones.shape[0], 1))), dim = 0).squeeze()\n",
    "\n",
    "# build dataloader\n",
    "dataset = torch.utils.data.TensorDataset(dataset, labels)"
   ],
   "metadata": {
    "id": "QJcweytq9bIw",
    "ExecuteTime": {
     "end_time": "2024-05-07T18:01:05.864900Z",
     "start_time": "2024-05-07T18:01:05.856584Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T16:45:03.864806Z",
     "start_time": "2024-05-06T16:45:03.863523Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# take hp combinations\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "print(f'\\nRunning experiment with batch size {BATCH_SIZE} and layers {NUM_LAYERS}\\n')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)\n",
    "time, loss_history = run_exp(LEARNING_RATE, NUM_LAYERS, BATCH_SIZE, NUM_EPOCHS, NUM_QUBITS, dataloader, loss_fn)\n",
    "\n",
    "# append time and hparams on file\n",
    "print(f'Average time per epoch: {time} - BS: {BATCH_SIZE} - LAYERS: {NUM_LAYERS}\\n')\n",
    "print('='*50)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maTMCm3R9eR5",
    "outputId": "de06c561-c4f0-4bc5-dc5e-e50f62e4ae69",
    "ExecuteTime": {
     "end_time": "2024-05-07T18:06:49.444820Z",
     "start_time": "2024-05-07T18:05:39.035246Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(loss_history)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "I1HtBbqlLggU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "outputId": "df065530-45d1-4625-fb8f-8d93e66db90f",
    "ExecuteTime": {
     "end_time": "2024-05-06T16:45:23.067256Z",
     "start_time": "2024-05-06T16:45:23.029604Z"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ]
}
