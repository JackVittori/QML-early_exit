{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install torch\n",
    "!pip install pennylane"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Z-WV1FoJoEo",
    "outputId": "201f7a41-dae9-4821-a654-869d6aa75f1a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "uWqP3StKUhx7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and visualize data\n",
    "standard_data_np = np.load(\"standard_data.npy\")\n",
    "anomalous_data_np = np.load(\"anomalous_data.npy\")\n",
    "\n",
    "plt.imshow(np.reshape(standard_data_np[0], (8,8)), cmap=\"gray\")\n",
    "plt.title(\"standard sample\")\n",
    "file_plot = \"standard_sample.png\"\n",
    "plt.savefig(file_plot)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(np.reshape(anomalous_data_np[4], (8,8)), cmap=\"gray\")\n",
    "plt.title(\"anomalous sample\")\n",
    "file_plot = \"anomalous_sample.png\"\n",
    "plt.savefig(file_plot)\n",
    "plt.close()\n",
    "\n",
    "# Define train set size, the rest will be used for test\n",
    "train_size = 5000\n",
    "\n",
    "train_set = torch.tensor(standard_data_np[0:train_size])\n",
    "standard_data_test = torch.tensor(standard_data_np[train_size:])\n",
    "anomalous_data_test = torch.tensor(anomalous_data_np)\n",
    "\n",
    "print(\"Len train set: \", len(train_set))\n",
    "print(\"Let test set: \", len(standard_data_test))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RS4ajANuu4gV",
    "outputId": "3b1bffc6-10e0-47d5-af0c-ad9bde87e059"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define quantum device\n",
    "dev = qml.device(\"default.qubit\", wires=6)\n",
    "\n",
    "def encoder_architecture(params, n_layers = 6, n_qubits = 6, q_compression = 3):\n",
    "  index = 0\n",
    "  for i in range(n_layers):\n",
    "      # Rotation layer\n",
    "      for j in range(n_qubits):\n",
    "          qml.RX(params[index], wires=j)\n",
    "          qml.RY(params[index + 1], wires=j)\n",
    "          qml.RZ(params[index + 2], wires=j)\n",
    "          index += 3\n",
    "      # Entangling layer\n",
    "      for j in range(n_qubits):\n",
    "          qml.CNOT(wires=[j, (j + 1) % n_qubits])\n",
    "  # Final rotations on compressed qubits\n",
    "  for j in range(q_compression):\n",
    "      qml.RX(params[index], wires=j)\n",
    "      qml.RY(params[index + 1], wires=j)\n",
    "      qml.RZ(params[index + 2], wires=j)\n",
    "      index += 3\n",
    "\n",
    "# Quantum encoder pipeline\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def encoder(params, state, return_state=False):\n",
    "    # Prepare initial state\n",
    "    qml.QubitStateVector(state, wires=range(6))\n",
    "    # Quantum circuit\n",
    "    encoder_architecture(params)\n",
    "    if return_state:\n",
    "      return qml.state()\n",
    "    # Return the Z expectation values for the compressed qubits\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(q_compression)]"
   ],
   "metadata": {
    "id": "GC7lQiD5U7uL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyper-parameters of the autoencoder\n",
    "n_layers = 6\n",
    "n_qubits = 6\n",
    "q_compression = 3\n",
    "\n",
    "# Initialize parameters\n",
    "n_params = (n_layers * n_qubits + q_compression) * 3\n",
    "params = Variable(torch.normal( mean=0. , std=0.1, size=(n_params,)), requires_grad=True)\n",
    "\n",
    "# Visualize quantum circuit\n",
    "state = train_set[0]"
   ],
   "metadata": {
    "id": "zUqZDI8PbqEo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "steps_per_epoch = int(train_size/batch_size)\n",
    "optimizer = torch.optim.Adam([params], lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1 , gamma=0.8)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "loss_history = []\n",
    "params_history = []\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "  tot_loss = 0.\n",
    "  for batch in data_loader:\n",
    "    optimizer.zero_grad()\n",
    "    expvals = encoder(params, batch)\n",
    "    loss = expvals[0].mean() + expvals[1].mean() + expvals[2].mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    tot_loss += loss.detach().numpy()\n",
    "  loss_history.append(tot_loss/steps_per_epoch)\n",
    "  params_history.append(params)\n",
    "  scheduler.step()\n",
    "  print(\"Epoch {}: avg_loss = {}\".format(epoch+1, tot_loss/steps_per_epoch))"
   ],
   "metadata": {
    "id": "Y3rZhm1dZbrV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3d047b0e-ec01-47d9-c0ab-f95d264c142f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Decoder\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def decoder(params, state):\n",
    "    # Prepare initial state\n",
    "    qml.QubitStateVector(state, wires=range(6))\n",
    "    # Quantum circuit (encoder inverse)\n",
    "    qml.adjoint(encoder_architecture)(params)\n",
    "    return qml.state()\n",
    "\n",
    "def prepare_decoder_input(latent_space):\n",
    "  decoder_input = np.zeros((64,), dtype=complex)\n",
    "  decoder_input[-len(latent_space):] = latent_space\n",
    "  # Normalize\n",
    "  norm = np.linalg.norm(decoder_input)\n",
    "  decoder_input = decoder_input/norm\n",
    "  return torch.tensor(decoder_input)\n",
    "\n",
    "# Visualize_decoder\n",
    "qml.drawer.use_style(\"black_white\")\n",
    "fig, ax = qml.draw_mpl(decoder)(params, standard_data_test[0])\n",
    "plt.title(\"Decoder\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "988KVtyNBAUI",
    "outputId": "a8e7de3b-20ce-4d53-8a15-bc00f7df94f3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Autoencoder simple use\n",
    "compression = 56 # for 3 out of 6 compressed qubits: compression = 2^5+2^4+2^3\n",
    "sample = standard_data_test[0]\n",
    "plt.imshow(np.reshape(sample, (8,8)), cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "with torch.no_grad():\n",
    "  final_state = encoder(params, sample, return_state = True).numpy()\n",
    "  latent_space = final_state[compression:]\n",
    "  decoder_input = prepare_decoder_input(latent_space)\n",
    "  reconstructed = np.absolute(decoder(params, decoder_input).numpy())\n",
    "plt.imshow(np.reshape(reconstructed, (8,8)), cmap=\"gray\")\n",
    "plt.title(\"Reconstructed\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "xpHtrw0LvwOv",
    "outputId": "38296349-c224-46f4-9c59-b0e8ef13c9c2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluation\n",
    "test_set_size = len(standard_data_test)\n",
    "print(\"Test set size: \", test_set_size)\n",
    "\n",
    "standard_data_loader = torch.utils.data.DataLoader(standard_data_test, batch_size=256, shuffle=False, drop_last=False)\n",
    "anomalous_data_loader = torch.utils.data.DataLoader(anomalous_data_test[0:len(standard_data_test)], batch_size=256, shuffle=False, drop_last=False)\n",
    "loss_s = np.asarray([])\n",
    "loss_a = np.asarray([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Standard data\n",
    "    for batch in standard_data_loader:\n",
    "      expvals = encoder(params, batch)\n",
    "      loss = expvals[0].numpy() + expvals[1].numpy() + expvals[2].numpy()\n",
    "      loss_s = np.concatenate([loss_s,loss])\n",
    "    # Anomalous data\n",
    "    for batch in anomalous_data_loader:\n",
    "      expvals = encoder(params, batch)\n",
    "      loss = expvals[0].numpy() + expvals[1].numpy() + expvals[2].numpy()\n",
    "      loss_a = np.concatenate([loss_a,loss])"
   ],
   "metadata": {
    "id": "eBp5OtdnB9Rr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4858222b-836a-4daf-ad41-638634ce53f3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Loss function plot\n",
    "plt.hist(loss_a, bins=60, histtype=\"step\", color=\"red\", label=\"Anomalous data\")\n",
    "plt.hist(loss_s, bins=60, histtype=\"step\", color=\"blue\", label=\"Standard data\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.xlabel(\"Loss value\")\n",
    "plt.title(\"Loss function distribution (MNIST dataset)\")\n",
    "plt.legend()\n",
    "file_plot = \"loss_distribution.png\"\n",
    "plt.savefig(file_plot)\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "id": "wN_MHMGJFIsT",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "outputId": "e3778854-90b4-44db-cc2f-11da9bd108ae"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Roc\n",
    "max1 = np.amax(loss_s)\n",
    "max2 = np.amax(loss_a)\n",
    "ma = max(max1, max2)\n",
    "min1 = np.amin(loss_s)\n",
    "min2 = np.amin(loss_a)\n",
    "mi = min(min1, min2)\n",
    "\n",
    "tot_neg = len(loss_s)\n",
    "tot_pos = len(loss_a)\n",
    "\n",
    "n_step = 100.0\n",
    "n_step_int = 100\n",
    "step = (ma - mi) / n_step\n",
    "fpr = []\n",
    "tpr = []\n",
    "for i in range(n_step_int):\n",
    "    treshold = i * step + mi\n",
    "    c = 0\n",
    "    for j in range(tot_neg):\n",
    "        if loss_s[j] > treshold:\n",
    "            c += 1\n",
    "    false_positive = c / float(tot_neg)\n",
    "    fpr.append(false_positive)\n",
    "    c = 0\n",
    "    for j in range(tot_pos):\n",
    "        if loss_a[j] > treshold:\n",
    "            c += 1\n",
    "    true_positive = c / float(tot_pos)\n",
    "    tpr.append(true_positive)\n",
    "\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "file_plot = \"ROC.png\"\n",
    "plt.savefig(file_plot)\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "id": "E_AbZCXkFePx",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "outputId": "f9860f48-3b74-4df6-83bc-b0221e08f6cb"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
