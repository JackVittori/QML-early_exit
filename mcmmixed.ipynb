{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-07T22:22:39.485698Z",
     "start_time": "2024-10-07T22:22:39.483822Z"
    }
   },
   "source": [
    "import random\n",
    "import pickle\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from data_utils import mnist_preparation\n",
    "from typing import Optional, Dict, List, Any\n",
    "from torch.utils.data import DataLoader, dataloader\n",
    "from tqdm import tqdm\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from pennylane import numpy as np"
   ],
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:22:42.180908Z",
     "start_time": "2024-10-07T22:22:39.908829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = [0,1,2,3]\n",
    "# Download MNIST and prepare transforms\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([\n",
    "                                transforms.Resize((16, 16)),  # Resize to 16x16\n",
    "                                transforms.ToTensor(),\n",
    "                                #transforms.Lambda(lambda img: add_salt_and_pepper_noise(img, salt_prob=0.1, pepper_prob=0.1)),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))  # Normalize\n",
    "                             ]))\n",
    "#train/vali/test 70/15/15 split, see data_utils.py for further details\n",
    "train_dataloader, validation_dataloader, test_dataloader = mnist_preparation(dataset=mnist, labels = labels, train_test_ratio=0.7,batch_size=64, vali_test_ratio=0.5)\n",
    "\n",
    "print(\"Images in the training set: \", len(train_dataloader.dataset), \"\\n Images in the validation set: \", len(validation_dataloader.dataset), \"\\n Images in the test set: \", len(test_dataloader.dataset))"
   ],
   "id": "cde3a8aa7a6c38bb",
   "execution_count": 45,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:22:42.184783Z",
     "start_time": "2024-10-07T22:22:42.181740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"/Users/jackvittori/Desktop/no-noise/norumore-training.pickle\", \"rb\") as file: \n",
    "    training_history = pickle.load(file)\n",
    "loss_history = training_history['loss_history']\n",
    "mcm_accuracy = training_history['mcm_accuracy']\n",
    "fm_accuracy = training_history['fm_accuracy']\n",
    "weights = training_history['model_params']"
   ],
   "id": "dbcd92bdf58f13a6",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:22:42.187533Z",
     "start_time": "2024-10-07T22:22:42.185452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for param in weights.values():\n",
    "    param.requires_grad = False"
   ],
   "id": "5d31132437e22ca7",
   "execution_count": 47,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:22:42.191149Z",
     "start_time": "2024-10-07T22:22:42.188641Z"
    }
   },
   "cell_type": "code",
   "source": "weights['layer_0']",
   "id": "2db82a98ad0d768a",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:22:43.346545Z",
     "start_time": "2024-10-07T22:22:43.344367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"with open(\"/Users/jackvittori/Desktop/4layerokkkk/weight4layer.pickle\", \"rb\") as file: \n",
    "    weights_small = pickle.load(file)\n",
    "for param in weights_small.values():\n",
    "    param.requires_grad = False\"\"\""
   ],
   "id": "2f395339b0b4e16b",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:22:44.012815Z",
     "start_time": "2024-10-07T22:22:44.010691Z"
    }
   },
   "cell_type": "code",
   "source": "weights",
   "id": "5bbf24f9546678c3",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:17:47.938001Z",
     "start_time": "2024-10-07T22:17:47.936450Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"mps\")",
   "id": "67dc7f6120481724",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# No noise ",
   "id": "1f4e8b314f3a6fc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:23:34.726942Z",
     "start_time": "2024-10-07T22:23:34.720805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = 0.12\n",
    "def early_evaluation_utils(state: torch.Tensor = None): \n",
    "    first_pair = [0,1]\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(wires = first_pair)\n",
    "\n",
    "def fully_evaluation_utils(state: torch.Tensor = None):\n",
    "    first_pair = [0,1]\n",
    "    second_pair = [2,3]\n",
    "    measurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "            \n",
    "    for w in first_pair: \n",
    "        measurements.append(qml.measure(wires=w, reset=False, postselect=None))\n",
    "    #m_0 = qml.measure(wires = 0, reset=False, postselect=None)\n",
    "    #m_1 = qml.measure(wires = 1, reset=False, postselect=None)\n",
    "    #print('ok meas 1')\n",
    "    for i in range(4, 8):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(op = measurements), qml.probs(wires=[2,3])\n",
    "\n",
    "mixed_device = qml.device(\"default.mixed\", wires=[0,1,2,3,4,5,6,7,8,9])\n",
    "late_qnode = qml.QNode(fully_evaluation_utils, mixed_device)\n",
    "early_qnode = qml.QNode(early_evaluation_utils, mixed_device)"
   ],
   "id": "1873fa92bd9bffbe",
   "execution_count": 57,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:23:35.091423Z",
     "start_time": "2024-10-07T22:23:35.087672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_routine(dataloader: DataLoader, threshold: float):\n",
    "    \n",
    "    evaluation_results = []\n",
    "    early_results = []\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    early_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    executed_layers = 0\n",
    "    \n",
    "    for i, (img, target) in tqdm(enumerate(dataloader.dataset)):\n",
    "            \n",
    "        img = img.type(torch.float64)\n",
    "        img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "        #mid circuit evaluation\n",
    "        early_probs = early_qnode(img)\n",
    "        early_prediction = torch.argmax(early_probs)\n",
    "        confidence = early_probs[early_prediction].item()\n",
    "        early_guess = early_prediction == target\n",
    "        early_results.append(early_guess.item())\n",
    "        \n",
    "        if confidence >= threshold:\n",
    "            evaluation_results.append(early_guess.item())\n",
    "            count_1 += 1\n",
    "            executed_layers += 4\n",
    "            if early_guess: \n",
    "                early_correct += 1\n",
    "                \n",
    "        else: \n",
    "            final_probs = late_qnode(img)\n",
    "            early_full, final_full = final_probs\n",
    "            final_predictions = torch.argmax(final_full)\n",
    "            final_guess = final_predictions == target\n",
    "            evaluation_results.append(final_guess.item())\n",
    "            count_2 += 1\n",
    "            executed_layers += 12\n",
    "            if final_guess: \n",
    "                final_correct += 1\n",
    "        \n",
    "    total_accuracy = sum([1 for i in evaluation_results if i == True])/len(evaluation_results)\n",
    "    early_total_accuracy = sum([1 for i in early_results if i == True])/len(early_results)\n",
    "    early_exited_accuracy = early_correct/count_1 if count_1 > 0 else 0\n",
    "    final_exited_accuracy = final_correct/count_2 if count_2 > 0 else 0   \n",
    "    \n",
    "    return total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers\n"
   ],
   "id": "c511d900a56da046",
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:23:42.375922Z",
     "start_time": "2024-10-07T22:23:42.373328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "def explain_evaluation(dataloader: DataLoader, threshold: List[float]):\n",
    "    summary_data = {\n",
    "    'Threshold': [],\n",
    "    'Total Accuracy': [],\n",
    "    '# early exited images': [],\n",
    "    'Early exited Accuracy': [],\n",
    "    'Early total accuracy': [],\n",
    "    '# final classified images': [],\n",
    "    'Final classified Accuracy': [],\n",
    "    \"Executed layers\": []}\n",
    "    \n",
    "    for t in tqdm(threshold):\n",
    "        total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers = evaluation_routine(dataloader, t)\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(total_accuracy)\n",
    "        summary_data['# early exited images'].append(count_1)\n",
    "        summary_data['Early exited Accuracy'].append(early_exited_accuracy)\n",
    "        summary_data['Early total accuracy'].append(early_total_accuracy)\n",
    "        summary_data['# final classified images'].append(count_2)\n",
    "        summary_data['Final classified Accuracy'].append(final_exited_accuracy)\n",
    "        summary_data['Executed layers'].append(executed_layers)\n",
    "        \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return summary_data, df"
   ],
   "id": "2f332ad251dc6978",
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:23:56.846161Z",
     "start_time": "2024-10-07T22:23:56.844089Z"
    }
   },
   "cell_type": "code",
   "source": "thresholds = [0.2505, 0.2510, 0.2515, 0.2520, 0.2525, 0.2530, 0.2535]",
   "id": "36e9489a4ceb80aa",
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:23:57.237061Z",
     "start_time": "2024-10-07T22:23:57.235017Z"
    }
   },
   "cell_type": "code",
   "source": "[0.2505, 0.2507, 0.2510, 0.2513, 0.2515, 0.2520]",
   "id": "43bac833ac78be2c",
   "execution_count": 61,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T08:02:45.846982Z",
     "start_time": "2024-10-07T22:23:58.233420Z"
    }
   },
   "cell_type": "code",
   "source": "summary, table = explain_evaluation(test_dataloader, thresholds)",
   "id": "f8764157dc3c5e52",
   "execution_count": 62,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T08:02:45.851880Z",
     "start_time": "2024-10-08T08:02:45.847971Z"
    }
   },
   "cell_type": "code",
   "source": "table",
   "id": "944352461ef66833",
   "execution_count": 63,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T05:02:31.198517Z",
     "start_time": "2024-10-07T05:02:31.190264Z"
    }
   },
   "cell_type": "code",
   "source": "summary",
   "id": "5aae91a8acfa335d",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T08:02:45.854480Z",
     "start_time": "2024-10-08T08:02:45.852424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ev_data = {\n",
    "    'summary': summary,\n",
    "    'table': table}\n",
    "import pickle\n",
    "with open(\"/Users/jackvittori/Desktop/DEPOLARIZING/tutte/noise.pickle\", \"wb\") as file:\n",
    "    pickle.dump(ev_data, file)"
   ],
   "id": "637eac3b668edc02",
   "execution_count": 64,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T19:26:41.818053Z",
     "start_time": "2024-10-03T19:26:41.816280Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5d7ac12de6f8eca8",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Noise 0.005",
   "id": "9c3bdb77c5af7051"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:02:26.400175Z",
     "start_time": "2024-10-04T04:02:26.393904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = 0.015\n",
    "\n",
    "def early_evaluation_utils(state: torch.Tensor = None): \n",
    "    first_pair = [0,1]\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(wires = first_pair)\n",
    "\n",
    "def fully_evaluation_utils(state: torch.Tensor = None):\n",
    "    first_pair = [0,1]\n",
    "    second_pair = [2,3]\n",
    "    measurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "            \n",
    "    for w in first_pair: \n",
    "        measurements.append(qml.measure(wires=w, reset=False, postselect=None))\n",
    "    for i in range(4, 8):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(op = measurements), qml.probs(wires=[2,3])\n",
    "\n",
    "mixed_device = qml.device(\"default.mixed\", wires=[0,1,2,3,4,5,6,7,8,9])\n",
    "late_qnode = qml.QNode(fully_evaluation_utils, mixed_device)\n",
    "early_qnode = qml.QNode(early_evaluation_utils, mixed_device)"
   ],
   "id": "1101f4abea673203",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:02:26.404233Z",
     "start_time": "2024-10-04T04:02:26.400765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_routine(dataloader: DataLoader, threshold: float):\n",
    "    \n",
    "    evaluation_results = []\n",
    "    early_results = []\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    early_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    executed_layers = 0\n",
    "    \n",
    "    for i, (img, target) in tqdm(enumerate(dataloader.dataset)):\n",
    "            \n",
    "        img = img.type(torch.float64)\n",
    "        img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "        \n",
    "        #mid circuit evaluation\n",
    "        early_probs = early_qnode(img)\n",
    "        early_prediction = torch.argmax(early_probs)\n",
    "        confidence = early_probs[early_prediction].item()\n",
    "        early_guess = early_prediction == target\n",
    "        early_results.append(early_guess.item())\n",
    "        \n",
    "        if confidence >= threshold:\n",
    "            #print('early')\n",
    "            evaluation_results.append(early_guess.item())\n",
    "            count_1 += 1\n",
    "            executed_layers += 4\n",
    "            if early_guess: \n",
    "                early_correct += 1\n",
    "                \n",
    "        else: \n",
    "            #print('post')\n",
    "            final_probs = late_qnode(img)\n",
    "            early_full, final_full = final_probs\n",
    "            final_predictions = torch.argmax(final_full)\n",
    "            final_guess = final_predictions == target\n",
    "            evaluation_results.append(final_guess.item())\n",
    "            count_2 += 1\n",
    "            executed_layers += 12\n",
    "            if final_guess: \n",
    "                final_correct += 1\n",
    "        \n",
    "    total_accuracy = sum([1 for i in evaluation_results if i == True])/len(evaluation_results)\n",
    "    early_total_accuracy = sum([1 for i in early_results if i == True])/len(early_results)\n",
    "    early_exited_accuracy = early_correct/count_1 if count_1 > 0 else 0\n",
    "    final_exited_accuracy = final_correct/count_2 if count_2 > 0 else 0   \n",
    "    \n",
    "    return total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers\n"
   ],
   "id": "88b2a8934d49e165",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:02:26.407243Z",
     "start_time": "2024-10-04T04:02:26.404777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "def explain_evaluation(dataloader: DataLoader, threshold: List[float]):\n",
    "    summary_data = {\n",
    "    'Threshold': [],\n",
    "    'Total Accuracy': [],\n",
    "    '# early exited images': [],\n",
    "    'Early exited Accuracy': [],\n",
    "    'Early total accuracy': [],\n",
    "    '# final classified images': [],\n",
    "    'Final classified Accuracy': [],\n",
    "    \"Executed layers\": []}\n",
    "    \n",
    "    for t in tqdm(threshold):\n",
    "        total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers = evaluation_routine(dataloader, t)\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(total_accuracy)\n",
    "        summary_data['# early exited images'].append(count_1)\n",
    "        summary_data['Early exited Accuracy'].append(early_exited_accuracy)\n",
    "        summary_data['Early total accuracy'].append(early_total_accuracy)\n",
    "        summary_data['# final classified images'].append(count_2)\n",
    "        summary_data['Final classified Accuracy'].append(final_exited_accuracy)\n",
    "        summary_data['Executed layers'].append(executed_layers)\n",
    "        \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return summary_data, df"
   ],
   "id": "99c63d79d32fef89",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:02:26.409255Z",
     "start_time": "2024-10-04T04:02:26.407822Z"
    }
   },
   "cell_type": "code",
   "source": "thresholds = [0.26, 0.28, 0.30, 0.32, 0.34, 0.36]",
   "id": "8c78105c6a112499",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:49:18.117246Z",
     "start_time": "2024-10-04T04:02:26.409750Z"
    }
   },
   "cell_type": "code",
   "source": "summary, table = explain_evaluation(test_dataloader, thresholds)",
   "id": "97b8296aaf368b54",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:49:18.120176Z",
     "start_time": "2024-10-04T11:49:18.117980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ev_data = {\n",
    "    'summary': summary,\n",
    "    'table': table}\n",
    "import pickle\n",
    "with open(\"/Users/jackvittori/Desktop/DEPOLARIZING/tutte/mcm0-015.pickle\", \"wb\") as file:\n",
    "    pickle.dump(ev_data, file)"
   ],
   "id": "682f7233459e66eb",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Noise 0.01",
   "id": "5218b428a154eeb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:49:18.127562Z",
     "start_time": "2024-10-04T11:49:18.121779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = 0.005\n",
    "\n",
    "def early_evaluation_utils(state: torch.Tensor = None): \n",
    "    first_pair = [0,1]\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(wires = first_pair)\n",
    "\n",
    "def fully_evaluation_utils(state: torch.Tensor = None):\n",
    "    first_pair = [0,1]\n",
    "    second_pair = [2,3]\n",
    "    measurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "            \n",
    "    for w in first_pair: \n",
    "        measurements.append(qml.measure(wires=w, reset=False, postselect=None))\n",
    "    #m_0 = qml.measure(wires = 0, reset=False, postselect=None)\n",
    "    #m_1 = qml.measure(wires = 1, reset=False, postselect=None)\n",
    "    #print('ok meas 1')\n",
    "    for i in range(4, 8):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(op = measurements), qml.probs(wires=[2,3])\n",
    "\n",
    "mixed_device = qml.device(\"default.mixed\", wires=[0,1,2,3,4,5,6,7,8,9])\n",
    "late_qnode = qml.QNode(fully_evaluation_utils, mixed_device)\n",
    "early_qnode = qml.QNode(early_evaluation_utils, mixed_device)"
   ],
   "id": "5391c5b515dc84a0",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:49:18.131475Z",
     "start_time": "2024-10-04T11:49:18.127999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_routine(dataloader: DataLoader, threshold: float):\n",
    "    \n",
    "    evaluation_results = []\n",
    "    early_results = []\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    early_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    executed_layers = 0\n",
    "    \n",
    "    for i, (img, target) in tqdm(enumerate(dataloader.dataset)):\n",
    "            \n",
    "        img = img.type(torch.float64)\n",
    "        img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "        \n",
    "        #mid circuit evaluation\n",
    "        early_probs = early_qnode(img)\n",
    "        early_prediction = torch.argmax(early_probs)\n",
    "        confidence = early_probs[early_prediction].item()\n",
    "        early_guess = early_prediction == target\n",
    "        early_results.append(early_guess.item())\n",
    "        \n",
    "        if confidence >= threshold:\n",
    "            #print('early')\n",
    "            evaluation_results.append(early_guess.item())\n",
    "            count_1 += 1\n",
    "            executed_layers += 4\n",
    "            if early_guess: \n",
    "                early_correct += 1\n",
    "                \n",
    "        else: \n",
    "            #print('post')\n",
    "            final_probs = late_qnode(img)\n",
    "            early_full, final_full = final_probs\n",
    "            final_predictions = torch.argmax(final_full)\n",
    "            final_guess = final_predictions == target\n",
    "            evaluation_results.append(final_guess.item())\n",
    "            count_2 += 1\n",
    "            executed_layers += 12\n",
    "            if final_guess: \n",
    "                final_correct += 1\n",
    "        \n",
    "    total_accuracy = sum([1 for i in evaluation_results if i == True])/len(evaluation_results)\n",
    "    early_total_accuracy = sum([1 for i in early_results if i == True])/len(early_results)\n",
    "    early_exited_accuracy = early_correct/count_1 if count_1 > 0 else 0\n",
    "    final_exited_accuracy = final_correct/count_2 if count_2 > 0 else 0   \n",
    "    \n",
    "    return total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers\n"
   ],
   "id": "6c36a0ec8bcd3cec",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:49:18.134508Z",
     "start_time": "2024-10-04T11:49:18.132064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "def explain_evaluation(dataloader: DataLoader, threshold: List[float]):\n",
    "    summary_data = {\n",
    "    'Threshold': [],\n",
    "    'Total Accuracy': [],\n",
    "    '# early exited images': [],\n",
    "    'Early exited Accuracy': [],\n",
    "    'Early total accuracy': [],\n",
    "    '# final classified images': [],\n",
    "    'Final classified Accuracy': [],\n",
    "    \"Executed layers\": []}\n",
    "    \n",
    "    for t in tqdm(threshold):\n",
    "        total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers = evaluation_routine(dataloader, t)\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(total_accuracy)\n",
    "        summary_data['# early exited images'].append(count_1)\n",
    "        summary_data['Early exited Accuracy'].append(early_exited_accuracy)\n",
    "        summary_data['Early total accuracy'].append(early_total_accuracy)\n",
    "        summary_data['# final classified images'].append(count_2)\n",
    "        summary_data['Final classified Accuracy'].append(final_exited_accuracy)\n",
    "        summary_data['Executed layers'].append(executed_layers)\n",
    "        \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return summary_data, df"
   ],
   "id": "6c9b4bd7318dcc76",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:49:18.136442Z",
     "start_time": "2024-10-04T11:49:18.135016Z"
    }
   },
   "cell_type": "code",
   "source": "thresholds = [0.26, 0.28, 0.30, 0.32, 0.34, 0.36]",
   "id": "7996a718d2a64a3b",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T18:33:00.965340Z",
     "start_time": "2024-10-04T11:49:18.136879Z"
    }
   },
   "cell_type": "code",
   "source": "summary, table = explain_evaluation(test_dataloader, thresholds)",
   "id": "f5d066ca488d55a0",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T18:33:00.969724Z",
     "start_time": "2024-10-04T18:33:00.965988Z"
    }
   },
   "cell_type": "code",
   "source": "table",
   "id": "980d881fc5d88a70",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T18:33:00.972686Z",
     "start_time": "2024-10-04T18:33:00.970219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ev_data = {\n",
    "    'summary': summary,\n",
    "    'table': table}\n",
    "import pickle\n",
    "with open(\"/Users/jackvittori/Desktop/DEPOLARIZING/tutte/mcm0-005.pickle\", \"wb\") as file:\n",
    "    pickle.dump(ev_data, file)"
   ],
   "id": "a178ddfa88e5ae2d",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Noise 0.015",
   "id": "961d067dd53c1332"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:21:03.501188Z",
     "start_time": "2024-10-03T00:21:03.495604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = 0.015\n",
    "\n",
    "def early_evaluation_utils(state: torch.Tensor = None): \n",
    "    first_pair = [0,1]\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(wires = first_pair)\n",
    "\n",
    "def fully_evaluation_utils(state: torch.Tensor = None):\n",
    "    first_pair = [0,1]\n",
    "    second_pair = [2,3]\n",
    "    measurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "            \n",
    "    for w in first_pair: \n",
    "        measurements.append(qml.measure(wires=w, reset=False, postselect=None))\n",
    "    #m_0 = qml.measure(wires = 0, reset=False, postselect=None)\n",
    "    #m_1 = qml.measure(wires = 1, reset=False, postselect=None)\n",
    "    #print('ok meas 1')\n",
    "    for i in range(4, 8):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(op = measurements), qml.probs(wires=[2,3])\n",
    "\n",
    "mixed_device = qml.device(\"default.mixed\", wires=[0,1,2,3,4,5,6,7,8,9])\n",
    "late_qnode = qml.QNode(fully_evaluation_utils, mixed_device)\n",
    "early_qnode = qml.QNode(early_evaluation_utils, mixed_device)"
   ],
   "id": "e7838d406f7c00f1",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:21:03.504871Z",
     "start_time": "2024-10-03T00:21:03.501680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_routine(dataloader: DataLoader, threshold: float):\n",
    "    \n",
    "    evaluation_results = []\n",
    "    early_results = []\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    early_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    executed_layers = 0\n",
    "    \n",
    "    for i, (img, target) in tqdm(enumerate(dataloader.dataset)):\n",
    "        if i == 500:\n",
    "            break \n",
    "            \n",
    "        img = img.type(torch.float64)\n",
    "        img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "        \n",
    "        #mid circuit evaluation\n",
    "        early_probs = early_qnode(img)\n",
    "        early_prediction = torch.argmax(early_probs)\n",
    "        confidence = early_probs[early_prediction].item()\n",
    "        early_guess = early_prediction == target\n",
    "        early_results.append(early_guess.item())\n",
    "        \n",
    "        if confidence >= threshold:\n",
    "            #print('early')\n",
    "            evaluation_results.append(early_guess.item())\n",
    "            count_1 += 1\n",
    "            executed_layers += 4\n",
    "            if early_guess: \n",
    "                early_correct += 1\n",
    "                \n",
    "        else: \n",
    "            #print('post')\n",
    "            final_probs = late_qnode(img)\n",
    "            early_full, final_full = final_probs\n",
    "            final_predictions = torch.argmax(final_full)\n",
    "            final_guess = final_predictions == target\n",
    "            evaluation_results.append(final_guess.item())\n",
    "            count_2 += 1\n",
    "            executed_layers += 12\n",
    "            if final_guess: \n",
    "                final_correct += 1\n",
    "        \n",
    "    total_accuracy = sum([1 for i in evaluation_results if i == True])/len(evaluation_results)\n",
    "    early_total_accuracy = sum([1 for i in early_results if i == True])/len(early_results)\n",
    "    early_exited_accuracy = early_correct/count_1 if count_1 > 0 else 0\n",
    "    final_exited_accuracy = final_correct/count_2 if count_2 > 0 else 0   \n",
    "    \n",
    "    return total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers\n"
   ],
   "id": "3171b02f3c7b96f0",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:21:03.507921Z",
     "start_time": "2024-10-03T00:21:03.505439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "def explain_evaluation(dataloader: DataLoader, threshold: List[float]):\n",
    "    summary_data = {\n",
    "    'Threshold': [],\n",
    "    'Total Accuracy': [],\n",
    "    '# early exited images': [],\n",
    "    'Early exited Accuracy': [],\n",
    "    'Early total accuracy': [],\n",
    "    '# final classified images': [],\n",
    "    'Final classified Accuracy': [],\n",
    "    \"Executed layers\": []}\n",
    "    \n",
    "    for t in tqdm(threshold):\n",
    "        total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers = evaluation_routine(dataloader, t)\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(total_accuracy)\n",
    "        summary_data['# early exited images'].append(count_1)\n",
    "        summary_data['Early exited Accuracy'].append(early_exited_accuracy)\n",
    "        summary_data['Early total accuracy'].append(early_total_accuracy)\n",
    "        summary_data['# final classified images'].append(count_2)\n",
    "        summary_data['Final classified Accuracy'].append(final_exited_accuracy)\n",
    "        summary_data['Executed layers'].append(executed_layers)\n",
    "        \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return summary_data, df"
   ],
   "id": "1d160731ae8e6592",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:21:03.509954Z",
     "start_time": "2024-10-03T00:21:03.508469Z"
    }
   },
   "cell_type": "code",
   "source": "thresholds = [0.26, 0.28, 0.30, 0.32, 0.34, 0.36]",
   "id": "a6e0875f54b5319c",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T01:19:24.985499Z",
     "start_time": "2024-10-03T00:21:03.510339Z"
    }
   },
   "cell_type": "code",
   "source": "summary, table = explain_evaluation(test_dataloader, thresholds)",
   "id": "d453b6294a906f2d",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T01:19:24.989804Z",
     "start_time": "2024-10-03T01:19:24.986025Z"
    }
   },
   "cell_type": "code",
   "source": "table",
   "id": "c88f246788bba475",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T01:19:24.992208Z",
     "start_time": "2024-10-03T01:19:24.990335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ev_data = {\n",
    "    'summary': summary,\n",
    "    'table': table}\n",
    "import pickle\n",
    "with open(\"/Users/jackvittori/Desktop/DEPOLARIZING/500immagini/mcm015.pickle\", \"wb\") as file:\n",
    "    pickle.dump(ev_data, file)"
   ],
   "id": "7eda1d6dbb40cf50",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Noise 0.2",
   "id": "1a4b695ccb327c62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T23:53:50.754974Z",
     "start_time": "2024-10-01T23:53:50.749244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = 0\n",
    "\n",
    "def early_evaluation_utils(state: torch.Tensor = None): \n",
    "    first_pair = [0,1]\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(wires = first_pair)\n",
    "\n",
    "def fully_evaluation_utils(state: torch.Tensor = None):\n",
    "    first_pair = [0,1]\n",
    "    second_pair = [2,3]\n",
    "    measurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "            \n",
    "    for w in first_pair: \n",
    "        measurements.append(qml.measure(wires=w, reset=False, postselect=None))\n",
    "    #m_0 = qml.measure(wires = 0, reset=False, postselect=None)\n",
    "    #m_1 = qml.measure(wires = 1, reset=False, postselect=None)\n",
    "    #print('ok meas 1')\n",
    "    for i in range(4, 8):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=p, wires=(j + 1) % 8)\n",
    "    \n",
    "    return qml.probs(op = measurements), qml.probs(wires=[2,3])\n",
    "\n",
    "mixed_device = qml.device(\"default.mixed\", wires=[0,1,2,3,4,5,6,7,8,9])\n",
    "late_qnode = qml.QNode(fully_evaluation_utils, mixed_device)\n",
    "early_qnode = qml.QNode(early_evaluation_utils, mixed_device)"
   ],
   "id": "907af8652f786898",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T23:53:50.758920Z",
     "start_time": "2024-10-01T23:53:50.755518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_routine(dataloader: DataLoader, threshold: float):\n",
    "    \n",
    "    evaluation_results = []\n",
    "    early_results = []\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    early_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    executed_layers = 0\n",
    "    \n",
    "    for i, (img, target) in tqdm(enumerate(dataloader.dataset)):\n",
    "        if i == 100:\n",
    "            break \n",
    "            \n",
    "        img = img.type(torch.float64)\n",
    "        img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "        \n",
    "        #mid circuit evaluation\n",
    "        early_probs = early_qnode(img)\n",
    "        early_prediction = torch.argmax(early_probs)\n",
    "        confidence = early_probs[early_prediction].item()\n",
    "        early_guess = early_prediction == target\n",
    "        early_results.append(early_guess.item())\n",
    "        \n",
    "        if confidence >= threshold:\n",
    "            #print('early')\n",
    "            evaluation_results.append(early_guess.item())\n",
    "            count_1 += 1\n",
    "            executed_layers += 4\n",
    "            if early_guess: \n",
    "                early_correct += 1\n",
    "                \n",
    "        else: \n",
    "            #print('post')\n",
    "            final_probs = late_qnode(img)\n",
    "            early_full, final_full = final_probs\n",
    "            final_predictions = torch.argmax(final_full)\n",
    "            final_guess = final_predictions == target\n",
    "            evaluation_results.append(final_guess.item())\n",
    "            count_2 += 1\n",
    "            executed_layers += 12\n",
    "            if final_guess: \n",
    "                final_correct += 1\n",
    "        \n",
    "    total_accuracy = sum([1 for i in evaluation_results if i == True])/len(evaluation_results)\n",
    "    early_total_accuracy = sum([1 for i in early_results if i == True])/len(early_results)\n",
    "    early_exited_accuracy = early_correct/count_1 if count_1 > 0 else 0\n",
    "    final_exited_accuracy = final_correct/count_2 if count_2 > 0 else 0   \n",
    "    \n",
    "    return total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers\n"
   ],
   "id": "c6c0d02e60bafdc5",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T23:53:50.762021Z",
     "start_time": "2024-10-01T23:53:50.759592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "def explain_evaluation(dataloader: DataLoader, threshold: List[float]):\n",
    "    summary_data = {\n",
    "    'Threshold': [],\n",
    "    'Total Accuracy': [],\n",
    "    '# early exited images': [],\n",
    "    'Early exited Accuracy': [],\n",
    "    'Early total accuracy': [],\n",
    "    '# final classified images': [],\n",
    "    'Final classified Accuracy': [],\n",
    "    \"Executed layers\": []}\n",
    "    \n",
    "    for t in tqdm(threshold):\n",
    "        total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers = evaluation_routine(dataloader, t)\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(total_accuracy)\n",
    "        summary_data['# early exited images'].append(count_1)\n",
    "        summary_data['Early exited Accuracy'].append(early_exited_accuracy)\n",
    "        summary_data['Early total accuracy'].append(early_total_accuracy)\n",
    "        summary_data['# final classified images'].append(count_2)\n",
    "        summary_data['Final classified Accuracy'].append(final_exited_accuracy)\n",
    "        summary_data['Executed layers'].append(executed_layers)\n",
    "        \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return summary_data, df"
   ],
   "id": "39c15ba6c329af8d",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T23:53:50.764068Z",
     "start_time": "2024-10-01T23:53:50.762498Z"
    }
   },
   "cell_type": "code",
   "source": "thresholds = [round(x * 0.01 + 0.26, 2) for x in range(25)]",
   "id": "d54bd11891ad93bd",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T00:50:16.478094Z",
     "start_time": "2024-10-01T23:53:50.764567Z"
    }
   },
   "cell_type": "code",
   "source": "summary, table = explain_evaluation(test_dataloader, thresholds)",
   "id": "150c65cb6540c6df",
   "execution_count": 39,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T00:50:16.483495Z",
     "start_time": "2024-10-02T00:50:16.478586Z"
    }
   },
   "cell_type": "code",
   "source": "table",
   "id": "27fc7c5d546b6cfb",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T00:50:16.489615Z",
     "start_time": "2024-10-02T00:50:16.487606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ev_data = {\n",
    "    'summary': summary,\n",
    "    'table': table}\n",
    "import pickle\n",
    "with open(\"/Users/jackvittori/Desktop/DEPOLARIZING/analitica/depomcm02.pickle\", \"wb\") as file:\n",
    "    pickle.dump(ev_data, file)"
   ],
   "id": "507596a393fd2a0f",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "de99916f8d2c89d8",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
