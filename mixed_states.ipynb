{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-30T16:07:32.356009Z",
     "start_time": "2024-09-30T16:07:32.353700Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from data_utils import mnist_preparation\n",
    "from typing import Optional, Dict, List, Any\n",
    "from torch.utils.data import DataLoader, dataloader\n",
    "from tqdm import tqdm\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T16:07:35.193605Z",
     "start_time": "2024-09-30T16:07:32.955284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = [0,1,2,3]\n",
    "# Download MNIST and prepare transforms\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([\n",
    "                                transforms.Resize((16, 16)),  # Resize to 16x16\n",
    "                                transforms.ToTensor(),\n",
    "                                #transforms.Lambda(lambda img: add_salt_and_pepper_noise(img, salt_prob=0.1, pepper_prob=0.1)),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))  # Normalize\n",
    "                             ]))\n",
    "#train/vali/test 70/15/15 split, see data_utils.py for further details\n",
    "train_dataloader, validation_dataloader, test_dataloader = mnist_preparation(dataset=mnist, labels = labels, train_test_ratio=0.7,batch_size=64, vali_test_ratio=0.5)\n",
    "\n",
    "print(\"Images in the training set: \", len(train_dataloader.dataset), \"\\n Images in the validation set: \", len(validation_dataloader.dataset), \"\\n Images in the test set: \", len(test_dataloader.dataset))"
   ],
   "id": "6561857f604aba66",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T16:07:42.021490Z",
     "start_time": "2024-09-30T16:07:42.012245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"import pickle\n",
    "with open('/Users/jackvittori/Desktop/allenamento26sett/om/trhistory.pickle', 'rb') as file: \n",
    "    tr_history = pickle.load(file)\n",
    "weights = tr_history['weights']\"\"\""
   ],
   "id": "142bb72e7c15025a",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T16:08:33.236679Z",
     "start_time": "2024-09-30T16:08:33.233238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open('/Users/jackvittori/Desktop/4layerokkkk/weight4layer.pickle', 'rb') as file: \n",
    "    weights = pickle.load(file)\n",
    "weights"
   ],
   "id": "a0bcc212cc8beabb",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T16:12:30.468856Z",
     "start_time": "2024-09-30T16:12:30.467040Z"
    }
   },
   "cell_type": "code",
   "source": "weights = {key: param.detach().numpy() for key, param in weights.items()}",
   "id": "f648885040a0434e",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:12:17.812757Z",
     "start_time": "2024-09-30T18:12:17.809856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mixed_device = qml.device('default.mixed', wires=8, shots = 1000)\n",
    "\n",
    "def quantum_function(state: torch.Tensor = None):\n",
    "    if state is not None:\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(weights[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(weights[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(weights[f'layer_{i}'][j, 2], wires=j)\n",
    "        \n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.DepolarizingChannel(p=0.07, wires=(j + 1) % 8)\n",
    "    return qml.probs()\n",
    "\n",
    "mixed_qnode = qml.QNode(quantum_function, device=mixed_device, interface = 'numpy')"
   ],
   "id": "79de9c7bc5b6cabc",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:23:17.988900Z",
     "start_time": "2024-09-30T18:12:18.050745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pennylane import numpy as np\n",
    "results = []\n",
    "test_accuracy = []\n",
    "for i, (img,targets) in tqdm(enumerate(test_dataloader.dataset)):\n",
    "    if i ==2000:\n",
    "        break\n",
    "    \"\"\"img = img.type(torch.float64)\n",
    "    img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "    probs = mixed_qnode(img, shots = 1000)\n",
    "    class_probabilities = torch.zeros(4, dtype=torch.float32)\n",
    "    for idx in range(4):\n",
    "    # Calculate the index range for each class\n",
    "        start_idx = int(idx * (256 / 4))\n",
    "        end_idx = int((idx + 1) * (256 / 4))\n",
    "        class_probabilities[idx] = torch.sum(probs[start_idx:end_idx])\n",
    "    print(torch.argmax(class_probabilities), targets)\"\"\"\n",
    "    \n",
    "    img = img.numpy().astype(np.float64)\n",
    "    targets = targets.numpy()\n",
    "    norm = np.linalg.norm(img)\n",
    "    norm = norm.reshape(-1,1)\n",
    "    img = img / norm\n",
    "    probs = mixed_qnode(img, shots = 1000)\n",
    "    class_probabilities = np.zeros(4, dtype=np.float32)\n",
    "    for idx in range(4):\n",
    "    # Calculate the index range for each class\n",
    "        start_idx = int(idx * (256 / 4))\n",
    "        end_idx = int((idx + 1) * (256 / 4))\n",
    "        class_probabilities[idx] = np.sum(probs[start_idx:end_idx])\n",
    "    results.append(np.argmax(class_probabilities)==targets)\n",
    "    \"\"\"\n",
    "    data = data.type(torch.float64)\n",
    "    data = data / torch.linalg.norm(data, dim = 1).view(-1, 1)\n",
    "    output = mixed_qnode(data).type(torch.float32)\n",
    "    probabilities = torch.zeros(output.shape[0], 4, dtype=torch.float32)\n",
    "    for idx in range(4):\n",
    "        # Calculate the index range for each class\n",
    "        start_idx = int(idx * (256 / 4))\n",
    "        end_idx = int((idx + 1) * (256 / 4))\n",
    "        probabilities[:, idx] = torch.sum(torch.abs(output[:, start_idx:end_idx]) ** 2, dim=1)\n",
    "        \n",
    "    predictions = torch.argmax(probabilities, dim = 1)\n",
    "    batch_accuracy = torch.sum(predictions == targets).item() / len(predictions)\n",
    "    #print(batch_accuracy)\n",
    "    test_accuracy.append(batch_accuracy)\n",
    "    #predictions = torch.argmax(output, dim=1)\n",
    "    #batch_accuracy = torch.sum(predictions == targets).item() / len(predictions)\n",
    "    #print(batch_accuracy)\"\"\"\n",
    " \n",
    "print(\"The accuracy over the test is \", sum(results)/len(results))    \n",
    "#print(\"The accuracy over the test is \", sum(test_accuracy)/len(test_accuracy))"
   ],
   "id": "3b1d3250a4b8b628",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pennylane import numpy as np\n",
    "results = []\n",
    "test_accuracy = []\n",
    "for i, (img,targets) in tqdm(enumerate(test_dataloader.dataset)):\n",
    "    #if i ==2000:\n",
    "     #   break\n",
    "    \"\"\"img = img.type(torch.float64)\n",
    "    img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "    probs = mixed_qnode(img, shots = 1000)\n",
    "    class_probabilities = torch.zeros(4, dtype=torch.float32)\n",
    "    for idx in range(4):\n",
    "    # Calculate the index range for each class\n",
    "        start_idx = int(idx * (256 / 4))\n",
    "        end_idx = int((idx + 1) * (256 / 4))\n",
    "        class_probabilities[idx] = torch.sum(probs[start_idx:end_idx])\n",
    "    print(torch.argmax(class_probabilities), targets)\"\"\"\n",
    "    \n",
    "    img = img.numpy().astype(np.float64)\n",
    "    targets = targets.numpy()\n",
    "    norm = np.linalg.norm(img)\n",
    "    norm = norm.reshape(-1,1)\n",
    "    img = img / norm\n",
    "    probs = mixed_qnode(img, shots = 1000)\n",
    "    class_probabilities = np.zeros(4, dtype=np.float32)\n",
    "    for idx in range(4):\n",
    "    # Calculate the index range for each class\n",
    "        start_idx = int(idx * (256 / 4))\n",
    "        end_idx = int((idx + 1) * (256 / 4))\n",
    "        class_probabilities[idx] = np.sum(probs[start_idx:end_idx])\n",
    "    results.append(np.argmax(class_probabilities)==targets)\n",
    "    \"\"\"\n",
    "    data = data.type(torch.float64)\n",
    "    data = data / torch.linalg.norm(data, dim = 1).view(-1, 1)\n",
    "    output = mixed_qnode(data).type(torch.float32)\n",
    "    probabilities = torch.zeros(output.shape[0], 4, dtype=torch.float32)\n",
    "    for idx in range(4):\n",
    "        # Calculate the index range for each class\n",
    "        start_idx = int(idx * (256 / 4))\n",
    "        end_idx = int((idx + 1) * (256 / 4))\n",
    "        probabilities[:, idx] = torch.sum(torch.abs(output[:, start_idx:end_idx]) ** 2, dim=1)\n",
    "        \n",
    "    predictions = torch.argmax(probabilities, dim = 1)\n",
    "    batch_accuracy = torch.sum(predictions == targets).item() / len(predictions)\n",
    "    #print(batch_accuracy)\n",
    "    test_accuracy.append(batch_accuracy)\n",
    "    #predictions = torch.argmax(output, dim=1)\n",
    "    #batch_accuracy = torch.sum(predictions == targets).item() / len(predictions)\n",
    "    #print(batch_accuracy)\"\"\"\n",
    " \n",
    "print(\"The accuracy over the test is \", sum(results)/len(results))    \n",
    "#print(\"The accuracy over the test is \", sum(test_accuracy)/len(test_accuracy))"
   ],
   "id": "b97a2caffa97c15f",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T18:07:06.675567Z",
     "start_time": "2024-09-29T18:07:06.467993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dati\n",
    "accuracy_class = [0.9230, 0.9180, 0.9130, 0.9040, 0.8834, 0.8349, 0.7157, 0.5584, 0.4348]\n",
    "class_p = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "\n",
    "# Creazione grafico\n",
    "plt.style.use('ggplot') \n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Titoli e etichette\n",
    "ax.set_title('Accuracy under classical noise condition', fontsize=16)\n",
    "ax.set_xlabel('P', fontsize=14)\n",
    "ax.set_ylabel('Accuracy', fontsize=14)\n",
    "ax.set_ylim(0.2, 1)\n",
    "\n",
    "# Tracciare i punti collegati\n",
    "ax.plot(class_p, accuracy_class, marker='o', color='b', label='Classical Accuracy')\n",
    "\n",
    "# Legenda\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Griglia e layout\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizzazione grafico\n",
    "plt.show()\n",
    "fig.savefig('/Users/jackvittori/Desktop/plots/noiseoriginale.png', dpi=300)"
   ],
   "id": "c7c50be6564ec1a9",
   "execution_count": 63,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:33:33.386412Z",
     "start_time": "2024-09-30T18:33:33.181267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dati\n",
    "accuarcy_dep = [0.9230, 0.8957, 0.8583, 0.7492, 0.5314, 0.4097, 0.3312, 0.2730]\n",
    "class_p = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]\n",
    "accuracy_4 = [0.8612, 0.8485, 0.8211, 0.7857, 0.7412, 0.7035, 0.6481, 0.5601]\n",
    "\n",
    "# Creazione grafico\n",
    "plt.style.use('ggplot') \n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Titoli e etichette\n",
    "ax.set_title('Accuracy under depolarizing effects', fontsize=16)\n",
    "ax.set_xlabel('Probability', fontsize=14)\n",
    "ax.set_ylabel('Accuracy', fontsize=14)\n",
    "ax.set_ylim(0.2, 1)\n",
    "\n",
    "# Tracciare i punti collegati\n",
    "ax.plot(class_p, accuarcy_dep, marker='o', color='b', label='8 layers')\n",
    "ax.plot(class_p, accuracy_4, marker='o', color='r', label='4 layers')\n",
    "\n",
    "# Legenda\n",
    "ax.legend(loc='lower left')\n",
    "\n",
    "# Griglia e layout\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizzazione grafico\n",
    "plt.show()\n",
    "fig.savefig('/Users/jackvittori/Desktop/plots/depnoiseoriginale.png', dpi=300)"
   ],
   "id": "d6d544776005c4bc",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "accuarcy_dep = [0.9230, 0.8957, 0.8583, 0.7492, 0.5314, 0.4097, 0.3112, 0.2730]",
   "id": "5cddf0791322c58e",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
