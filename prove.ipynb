{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:37:12.350292Z",
     "start_time": "2024-05-06T19:37:10.325210Z"
    }
   },
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from circuit_model_II import QuantumCircuit, FullQuantumModel\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "num_qubits = 8\n",
    "num_layers = 5\n",
    "model = FullQuantumModel(num_qubits, num_layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:37:12.353678Z",
     "start_time": "2024-05-06T19:37:12.351360Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset preparation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:37:14.860965Z",
     "start_time": "2024-05-06T19:37:12.354205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download MNIST and prepare transforms\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                transforms.Resize((16, 16)),  # Resize to 16x16\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))  # Normalize\n",
    "                             ]))\n",
    "# Filter for zeros and ones\n",
    "data = []\n",
    "targets = []\n",
    "for image, label in mnist_train:\n",
    "    if label in [0, 1]:\n",
    "        data.append(image.squeeze())\n",
    "        targets.append(label)\n",
    "\n",
    "data = torch.stack(data)\n",
    "targets = torch.tensor(targets)\n",
    "# Select 1024 zeros and 1024 ones for speed\n",
    "zeros_indices = (targets == 0)\n",
    "ones_indices = (targets == 1)\n",
    "\n",
    "zeros = data[zeros_indices]\n",
    "ones = data[ones_indices]\n",
    "\n",
    "# take a subsample of the dataset for simplicity\n",
    "zeros = zeros[:1024]\n",
    "ones = ones[:1024]\n",
    "\n",
    "#normalize between 0 and 1\n",
    "zeros_max = torch.max(zeros.reshape(-1, 16*16), dim = 1)\n",
    "zeros_min = torch.min(zeros.reshape(-1, 16*16), dim = 1)\n",
    "ones_max = torch.max(ones.reshape(-1, 16*16), dim = 1)\n",
    "ones_min = torch.min(ones.reshape(-1, 16*16), dim = 1)\n",
    "\n",
    "def normalize(imgs):\n",
    "  maxes, _ = torch.max(imgs.reshape(-1, 16*16), dim = 1)\n",
    "  mins, _ = torch.min(imgs.reshape(-1, 16*16), dim = 1)\n",
    "\n",
    "  mins = mins.unsqueeze(1).unsqueeze(2)\n",
    "  maxes = maxes.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "  return (imgs-mins)/(maxes-mins)\n",
    "\n",
    "zeros = normalize(zeros)\n",
    "ones = normalize(ones)\n",
    "\n",
    "# assert images have min 0 and max 1 within an error of 1e-5\n",
    "assert torch.allclose(zeros.min(), torch.tensor(0., dtype = torch.float32), atol=1e-5)\n",
    "assert torch.allclose(zeros.max(), torch.tensor(1., dtype = torch.float32), atol=1e-5)\n",
    "assert torch.allclose(ones.min(), torch.tensor(0., dtype = torch.float32), atol=1e-5)\n",
    "assert torch.allclose(ones.max(), torch.tensor(1., dtype = torch.float32), atol=1e-5)\n",
    "\n",
    "# concatenate the two datasets\n",
    "zeros = zeros.flatten(start_dim = 1)\n",
    "ones = ones.flatten(start_dim = 1)\n",
    "dataset = torch.cat((zeros, ones), dim = 0)\n",
    "\n",
    "# add labels\n",
    "labels = torch.cat((torch.zeros((zeros.shape[0], 1)), torch.ones((ones.shape[0], 1))), dim = 0).squeeze()\n",
    "\n",
    "# build dataloader\n",
    "dataset = torch.utils.data.TensorDataset(dataset, labels)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:37:14.865308Z",
     "start_time": "2024-05-06T19:37:14.861940Z"
    }
   },
   "cell_type": "code",
   "source": "type(dataloader.batch_size)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model training"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:37:26.020105Z",
     "start_time": "2024-05-06T19:37:24.575231Z"
    }
   },
   "cell_type": "code",
   "source": "type(model.fit(dataloader=dataloader, learning_rate=0.01, epochs=1, num_layers_to_execute = 2))",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 64/64 [00:01<00:00, 44.97it/s, accuracy=1, loss=0.403]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per epoch:  1.4402949810028076\n",
      "Epoch:  0 Loss:  0.40266889333724976\n",
      "Accuracy:  1.0\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:37:19.202525Z",
     "start_time": "2024-05-06T19:37:19.196239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in model.parameters():\n",
    "    print(i) "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1259, 0.3466, 0.9910],\n",
      "        [0.8657, 0.9612, 0.4612],\n",
      "        [0.7805, 0.8487, 0.4308],\n",
      "        [0.0870, 0.7718, 0.3512],\n",
      "        [0.9045, 0.2161, 0.2771],\n",
      "        [0.4164, 0.4911, 0.4528],\n",
      "        [0.0973, 0.9993, 0.6357],\n",
      "        [0.1389, 0.3376, 0.3310]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.8652, 0.8335, 0.5623],\n",
      "        [0.7110, 0.6649, 0.1241],\n",
      "        [0.2517, 0.6070, 0.3412],\n",
      "        [0.5539, 0.5615, 0.3149],\n",
      "        [0.0444, 0.3797, 0.1786],\n",
      "        [0.5347, 0.1856, 0.1057],\n",
      "        [0.1850, 0.3459, 0.6451],\n",
      "        [0.1199, 0.0703, 0.8707]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1950, 0.7310, 0.8196],\n",
      "        [0.3256, 0.8464, 0.1401],\n",
      "        [0.5943, 0.8618, 0.8901],\n",
      "        [0.1191, 0.2418, 0.3751],\n",
      "        [0.9871, 0.5877, 0.6899],\n",
      "        [0.0342, 0.7633, 0.5293],\n",
      "        [0.5439, 0.8720, 0.9959],\n",
      "        [0.6331, 0.0753, 0.7506]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.5530, 0.6335, 0.8593],\n",
      "        [0.5926, 0.7884, 0.0436],\n",
      "        [0.9184, 0.9975, 0.3656],\n",
      "        [0.7753, 0.3362, 0.3268],\n",
      "        [0.8906, 0.7035, 0.5859],\n",
      "        [0.6586, 0.1968, 0.1481],\n",
      "        [0.3305, 0.7229, 0.6461],\n",
      "        [0.5140, 0.1749, 0.2269]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.5214, 0.3001, 0.0126],\n",
      "        [0.5774, 0.5410, 0.4015],\n",
      "        [0.4986, 0.4668, 0.7246],\n",
      "        [0.5274, 0.1740, 0.8854],\n",
      "        [0.3447, 0.6271, 0.2259],\n",
      "        [0.2441, 0.1679, 0.4932],\n",
      "        [0.1531, 0.9294, 0.5849],\n",
      "        [0.2358, 0.9543, 0.1246]], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:37:29.915401Z",
     "start_time": "2024-05-06T19:37:29.908990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4217, -0.1460,  0.6143],\n",
      "        [ 0.4643,  0.2922,  0.9641],\n",
      "        [ 0.6993,  0.7714,  0.4006],\n",
      "        [-0.3034,  1.3796,  0.7367],\n",
      "        [ 1.2409,  0.0914,  0.0301],\n",
      "        [-0.0668,  0.1032, -0.0940],\n",
      "        [ 0.5682,  1.3219,  0.2524],\n",
      "        [-0.3050, -0.0117,  1.0452]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8208,  0.8103,  0.5783],\n",
      "        [ 0.4210,  0.2859,  0.1263],\n",
      "        [-0.1307,  0.0789,  0.3703],\n",
      "        [-0.0428,  0.0444,  0.3014],\n",
      "        [-0.1649,  0.1395,  0.1812],\n",
      "        [ 0.0893, -0.0510,  0.1188],\n",
      "        [ 0.6903,  0.5038,  0.6650],\n",
      "        [ 0.3607,  0.3417,  0.9038]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1950, 0.7310, 0.8196],\n",
      "        [0.3256, 0.8464, 0.1401],\n",
      "        [0.5943, 0.8618, 0.8901],\n",
      "        [0.1191, 0.2418, 0.3751],\n",
      "        [0.9871, 0.5877, 0.6899],\n",
      "        [0.0342, 0.7633, 0.5293],\n",
      "        [0.5439, 0.8720, 0.9959],\n",
      "        [0.6331, 0.0753, 0.7506]])\n",
      "Parameter containing:\n",
      "tensor([[0.5530, 0.6335, 0.8593],\n",
      "        [0.5926, 0.7884, 0.0436],\n",
      "        [0.9184, 0.9975, 0.3656],\n",
      "        [0.7753, 0.3362, 0.3268],\n",
      "        [0.8906, 0.7035, 0.5859],\n",
      "        [0.6586, 0.1968, 0.1481],\n",
      "        [0.3305, 0.7229, 0.6461],\n",
      "        [0.5140, 0.1749, 0.2269]])\n",
      "Parameter containing:\n",
      "tensor([[0.5214, 0.3001, 0.0126],\n",
      "        [0.5774, 0.5410, 0.4015],\n",
      "        [0.4986, 0.4668, 0.7246],\n",
      "        [0.5274, 0.1740, 0.8854],\n",
      "        [0.3447, 0.6271, 0.2259],\n",
      "        [0.2441, 0.1679, 0.4932],\n",
      "        [0.1531, 0.9294, 0.5849],\n",
      "        [0.2358, 0.9543, 0.1246]])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:36:16.427133Z",
     "start_time": "2024-05-06T19:36:16.424432Z"
    }
   },
   "cell_type": "code",
   "source": "model.unfreeze_layers([0,1])",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:02:10.437242Z",
     "start_time": "2024-05-06T18:02:10.428951Z"
    }
   },
   "cell_type": "code",
   "source": "torch.torch.linalg.norm(circuit(example), dim = 1)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:02:02.674390Z",
     "start_time": "2024-05-06T18:02:02.665458Z"
    }
   },
   "cell_type": "code",
   "source": "§torch.torch.linalg.norm(example, dim = 1)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:20:18.723294Z",
     "start_time": "2024-05-06T19:20:18.720104Z"
    }
   },
   "cell_type": "code",
   "source": "list(range(model.num_layers))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:27:22.114976Z",
     "start_time": "2024-05-06T19:27:22.112726Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4209440489.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[15], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    [element for element in list(range(model.num_layers)) if not in list(range(3))]\u001B[0m\n\u001B[0m                                                                 ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:28:51.403103Z",
     "start_time": "2024-05-06T19:28:51.399514Z"
    }
   },
   "cell_type": "code",
   "source": "[element for element in range(model.num_layers) if element not in list(range(3))]\n",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
