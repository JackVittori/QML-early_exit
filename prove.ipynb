{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:08:13.671175Z",
     "start_time": "2024-05-07T14:08:13.667356Z"
    }
   },
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from circuit_model_II import QuantumCircuit, FullQuantumModel\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader, random_split"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "num_qubits = 8\n",
    "num_layers = 5\n",
    "model = FullQuantumModel(num_qubits, num_layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:37:49.122353Z",
     "start_time": "2024-05-07T13:37:49.119462Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.draw(style)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset preparation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T14:08:04.920381Z",
     "start_time": "2024-05-07T14:08:02.179725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download MNIST and prepare transforms\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                transforms.Resize((16, 16)),  # Resize to 16x16\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))  # Normalize\n",
    "                             ]))\n",
    "# Filter for zeros and ones\n",
    "data = []\n",
    "targets = []\n",
    "for image, label in mnist_train:\n",
    "    if label in [0, 1]:\n",
    "        data.append(image.squeeze())\n",
    "        targets.append(label)\n",
    "\n",
    "data = torch.stack(data)\n",
    "targets = torch.tensor(targets)\n",
    "# Select 1024 zeros and 1024 ones for speed\n",
    "zeros_indices = (targets == 0)\n",
    "ones_indices = (targets == 1)\n",
    "\n",
    "zeros = data[zeros_indices]\n",
    "ones = data[ones_indices]\n",
    "\n",
    "#normalize between 0 and 1\n",
    "zeros_max = torch.max(zeros.reshape(-1, 16*16), dim = 1)\n",
    "zeros_min = torch.min(zeros.reshape(-1, 16*16), dim = 1)\n",
    "ones_max = torch.max(ones.reshape(-1, 16*16), dim = 1)\n",
    "ones_min = torch.min(ones.reshape(-1, 16*16), dim = 1)\n",
    "\n",
    "def normalize(imgs):\n",
    "  maxes, _ = torch.max(imgs.reshape(-1, 16*16), dim = 1)\n",
    "  mins, _ = torch.min(imgs.reshape(-1, 16*16), dim = 1)\n",
    "\n",
    "  mins = mins.unsqueeze(1).unsqueeze(2)\n",
    "  maxes = maxes.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "  return (imgs-mins)/(maxes-mins)\n",
    "\n",
    "zeros = normalize(zeros)\n",
    "ones = normalize(ones)\n",
    "\n",
    "# assert images have min 0 and max 1 within an error of 1e-5\n",
    "assert torch.allclose(zeros.min(), torch.tensor(0., dtype = torch.float32), atol=1e-5)\n",
    "assert torch.allclose(zeros.max(), torch.tensor(1., dtype = torch.float32), atol=1e-5)\n",
    "assert torch.allclose(ones.min(), torch.tensor(0., dtype = torch.float32), atol=1e-5)\n",
    "assert torch.allclose(ones.max(), torch.tensor(1., dtype = torch.float32), atol=1e-5)\n",
    "\n",
    "# concatenate the two datasets\n",
    "zeros = zeros.flatten(start_dim = 1)\n",
    "ones = ones.flatten(start_dim = 1)\n",
    "dataset = torch.cat((zeros, ones), dim = 0)\n",
    "\n",
    "# add labels\n",
    "labels = torch.cat((torch.zeros((zeros.shape[0], 1)), torch.ones((ones.shape[0], 1))), dim = 0).squeeze()\n",
    "\n",
    "# build dataloader\n",
    "dataset = torch.utils.data.TensorDataset(dataset, labels)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T14:08:18.128466Z",
     "start_time": "2024-05-07T14:08:18.121539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#train/test split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T14:08:35.061785Z",
     "start_time": "2024-05-07T14:08:35.057384Z"
    }
   },
   "cell_type": "code",
   "source": "len(test_dataset)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model training"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T13:38:51.046325Z",
     "start_time": "2024-05-07T13:38:49.631193Z"
    }
   },
   "cell_type": "code",
   "source": "type(model.fit(dataloader=train_dataloader, learning_rate=0.01, epochs=1, num_layers_to_execute = 2))",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 64/64 [00:01<00:00, 46.14it/s, accuracy=0.969, loss=0.445]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per epoch:  1.410733699798584\n",
      "Epoch:  0 Loss:  0.4453395903110504\n",
      "Accuracy:  0.96875\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T13:41:29.458990Z",
     "start_time": "2024-05-07T13:41:29.454831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 6.4518e-01,  2.7357e-01,  1.3663e+00],\n",
      "        [-3.5419e-01,  7.6826e-01,  1.1332e+00],\n",
      "        [ 3.0931e-01, -3.1503e-01,  2.2945e-01],\n",
      "        [ 9.5090e-01,  6.5840e-01,  1.3437e+00],\n",
      "        [ 5.4103e-01, -1.6942e-02,  3.6131e-01],\n",
      "        [ 1.1233e+00,  2.7824e-01,  4.4224e-01],\n",
      "        [ 5.5193e-01,  1.0022e-03,  4.9343e-01],\n",
      "        [ 1.3166e-01,  1.1371e+00,  5.5685e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8050,  0.5232,  0.0579],\n",
      "        [ 0.9479,  0.1219,  0.3449],\n",
      "        [ 1.0585,  0.7306,  0.8181],\n",
      "        [ 1.3893, -0.3028,  0.9060],\n",
      "        [ 0.9597,  0.1089,  0.5592],\n",
      "        [ 0.8824,  0.0786,  0.8563],\n",
      "        [ 1.4634,  0.0185,  0.2640],\n",
      "        [ 0.3201,  1.3131,  0.7878]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.8994, 0.4576, 0.6736],\n",
      "        [0.3294, 0.2796, 0.3973],\n",
      "        [0.6277, 0.0261, 0.2352],\n",
      "        [0.9228, 0.7249, 0.3469],\n",
      "        [0.0523, 0.6643, 0.7118],\n",
      "        [0.0241, 0.1838, 0.6101],\n",
      "        [0.9041, 0.2390, 0.9927],\n",
      "        [0.3093, 0.6613, 0.5038]])\n",
      "Parameter containing:\n",
      "tensor([[0.0236, 0.2702, 0.0910],\n",
      "        [0.2759, 0.6825, 0.4345],\n",
      "        [0.3167, 0.6982, 0.3545],\n",
      "        [0.4298, 0.4165, 0.2582],\n",
      "        [0.1773, 0.0313, 0.6452],\n",
      "        [0.6055, 0.9879, 0.2037],\n",
      "        [0.7939, 0.1376, 0.9074],\n",
      "        [0.2107, 0.1974, 0.7268]])\n",
      "Parameter containing:\n",
      "tensor([[0.8552, 0.1989, 0.7053],\n",
      "        [0.6699, 0.2695, 0.7181],\n",
      "        [0.5682, 0.9056, 0.3393],\n",
      "        [0.1818, 0.3234, 0.0364],\n",
      "        [0.2093, 0.6081, 0.3519],\n",
      "        [0.9439, 0.5314, 0.9325],\n",
      "        [0.3160, 0.6534, 0.1572],\n",
      "        [0.5469, 0.2643, 0.0749]])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
