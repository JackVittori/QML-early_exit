{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:46:07.165347Z",
     "start_time": "2024-09-26T21:46:07.150893Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from data_utils import mnist_preparation, add_salt_and_pepper_noise \n",
    "from evaluationUtils import calculate_mcm_accuracy\n",
    "from tqdm import tqdm\n",
    "import matplotlib as plt\n",
    "from mcmadaptablemodel import MCMQuantumModel, MCMCircuit\n",
    "from pennylane import Device\n",
    "from pennylane.measurements import StateMP\n",
    "from torch.nn import Module, ParameterDict\n",
    "import matplotlib.pyplot as plt\n",
    "from OriginalModel import FullQuantumModel, QuantumCircuit\n",
    "import warnings\n",
    "from typing import Optional, Dict, List, Any\n",
    "from torch.utils.data import DataLoader, dataloader\n",
    "from time import time\n",
    "import math\n",
    "from pennylane.measurements import MidMeasureMP\n",
    "torch.manual_seed(1234)"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T21:46:09.617816Z",
     "start_time": "2024-09-26T21:46:07.526470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = [0,1,2,3]\n",
    "# Download MNIST and prepare transforms\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([\n",
    "                                transforms.Resize((16, 16)),  # Resize to 16x16\n",
    "                                transforms.ToTensor(),\n",
    "                                #transforms.Lambda(lambda img: add_salt_and_pepper_noise(img, salt_prob=0.1, pepper_prob=0.1)),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))  # Normalize\n",
    "                             ]))\n",
    "#train/vali/test 70/15/15 split, see data_utils.py for further details\n",
    "train_dataloader, validation_dataloader, test_dataloader = mnist_preparation(dataset=mnist, labels = labels, train_test_ratio=0.7,batch_size=64, vali_test_ratio=0.5)\n",
    "\n",
    "print(\"Images in the training set: \", len(train_dataloader.dataset), \"\\n Images in the validation set: \", len(validation_dataloader.dataset), \"\\n Images in the test set: \", len(test_dataloader.dataset))"
   ],
   "id": "ff46f23147361ea9",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T21:46:09.621547Z",
     "start_time": "2024-09-26T21:46:09.618677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open(\"/Users/jackvittori/Desktop/no-noise/norumore-training.pickle\", \"rb\") as file: \n",
    "    training_history = pickle.load(file)\n",
    "loss_history = training_history['loss_history']\n",
    "mcm_accuracy = training_history['mcm_accuracy']\n",
    "fm_accuracy = training_history['fm_accuracy']\n",
    "weights = training_history['model_params']"
   ],
   "id": "c77c17bebb876875",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T21:46:44.599852Z",
     "start_time": "2024-09-26T21:46:44.587721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def early_evaluation_utils(params: Dict, prob: float, state: torch.Tensor = None): \n",
    "    first_pair = [0,1]\n",
    "    measurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(params[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(params[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(params[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.BitFlip(p=prob, wires=(j + 1) % 8)\n",
    "    \n",
    "    for w in first_pair: \n",
    "        measurements.append(qml.measure(wires=w)) #measure first pair of qubits\n",
    "    return measurements\n",
    "\n",
    "def fully_evaluation_utils(params: Dict, prob: float, state: torch.Tensor = None):\n",
    "    first_pair = [0,1]\n",
    "    second_pair = [2,3]\n",
    "    mcasurements = []\n",
    "    if state is not None:\n",
    "        # state vector initialization with input\n",
    "        qml.QubitStateVector(state, wires=range(8))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            qml.RX(params[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(params[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(params[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "            qml.BitFlip(p=prob, wires=(j + 1) % 8)\n",
    "            \n",
    "    for w in first_pair: \n",
    "        mcasurements.append(qml.measure(wires=w)) #measure first pair of qubits\n",
    "\n",
    "    for i in range(4, 8):\n",
    "        for j in range(8):\n",
    "            qml.RX(params[f'layer_{i}'][j, 0], wires=j)\n",
    "            qml.RY(params[f'layer_{i}'][j, 1], wires=j)\n",
    "            qml.RZ(params[f'layer_{i}'][j, 2], wires=j)\n",
    "        for j in range(8):\n",
    "            qml.CNOT(wires=[j, (j + 1) % 8])\n",
    "\n",
    "    for w in second_pair:\n",
    "        mcasurements.append(qml.measure(wires=w))\n",
    "\n",
    "    return mcasurements\n",
    "\n",
    "dev = qml.device(\"default.mixed\", wires=8)\n",
    "@qml.qnode(dev)  \n",
    "def early_evaluation_ansatz(params: Dict, prob: float, state: torch.Tensor = None):\n",
    "    early_measurement = early_evaluation_utils(params=params, prob=prob, state=state)\n",
    "    return qml.probs(op=early_measurement)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def fully_evaluation_ansatz(params: Dict, prob:float, state: torch.Tensor = None):\n",
    "    measurements = fully_evaluation_utils(params=params, prob=prob, state=state)\n",
    "    mid_measurement = measurements[:2]\n",
    "    final_measurement = measurements[2:]\n",
    "    return qml.probs(op=mid_measurement), qml.probs(op=final_measurement)"
   ],
   "id": "a353519c06a70826",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T21:46:48.386272Z",
     "start_time": "2024-09-26T21:46:48.379264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_routine(dataloader: DataLoader, parameters: Dict, threshold: float, prob:float):\n",
    "    \n",
    "    evaluation_results = []\n",
    "    early_results = []\n",
    "    count_1 = 0 #counter for early classified images\n",
    "    count_2 = 0 #counter for final classified images\n",
    "    early_correct = 0 #counter for correctly early classified images \n",
    "    final_correct = 0 #counter for correctly final classified images\n",
    "    executed_layers = 0\n",
    "    for img, target in dataloader.dataset:\n",
    "        #img normalization\n",
    "        img = img / torch.linalg.norm(img).view(-1, 1)\n",
    "        \n",
    "        #mid circuit evaluation\n",
    "        early_probs = early_evaluation_ansatz(params=parameters, prob=prob, state=img)\n",
    "        early_prediction = torch.argmax(early_probs, dim=1)\n",
    "        confidence = early_probs[0, early_prediction].item()\n",
    "        early_guess = early_prediction == target\n",
    "        early_results.append(early_guess.item())\n",
    "        \n",
    "        if confidence >= threshold:\n",
    "            evaluation_results.append(early_guess.item())\n",
    "            count_1 += 1\n",
    "            executed_layers += 4\n",
    "            if early_guess: \n",
    "                early_correct += 1\n",
    "            \n",
    "        else: \n",
    "            final_probs = fully_evaluation_ansatz(params=parameters, prob = prob, state=img)\n",
    "            early_full, final_full = final_probs\n",
    "            final_predictions = torch.argmax(final_full, dim=1)\n",
    "            final_guess = final_predictions == target\n",
    "            evaluation_results.append(final_guess.item())\n",
    "            count_2 += 1\n",
    "            executed_layers += 12\n",
    "            \n",
    "            if final_guess: \n",
    "                final_correct += 1\n",
    "    total_accuracy = sum([1 for i in evaluation_results if i == True])/len(evaluation_results)\n",
    "    early_total_accuracy = sum([1 for i in early_results if i == True])/len(early_results)\n",
    "    early_exited_accuracy = early_correct/count_1 if count_1 > 0 else 0\n",
    "    final_exited_accuracy = final_correct/count_2 if count_2 > 0 else 0\n",
    "    \n",
    "    return total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers"
   ],
   "id": "4de87170af658745",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T21:46:49.439272Z",
     "start_time": "2024-09-26T21:46:49.436192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explain_evaluation(dataloader: DataLoader, parameters: Dict, prob: float, threshold: List[float]):\n",
    "    summary_data = {\n",
    "    'Threshold': [],\n",
    "    'Total Accuracy': [],\n",
    "    '# early exited images': [],\n",
    "    'Early exited Accuracy': [],\n",
    "    'Early total accuracy': [],\n",
    "    '# final classified images': [],\n",
    "    'Final classified Accuracy': [],\n",
    "    \"Executed layers\": []}\n",
    "    \n",
    "    for t in tqdm(threshold):\n",
    "        total_accuracy, early_total_accuracy, early_exited_accuracy, count_1, final_exited_accuracy, count_2, executed_layers = evaluation_routine(dataloader, parameters, t, prob=prob)\n",
    "        summary_data['Threshold'].append(t)\n",
    "        summary_data['Total Accuracy'].append(total_accuracy)\n",
    "        summary_data['# early exited images'].append(count_1)\n",
    "        summary_data['Early exited Accuracy'].append(early_exited_accuracy)\n",
    "        summary_data['Early total accuracy'].append(early_total_accuracy)\n",
    "        summary_data['# final classified images'].append(count_2)\n",
    "        summary_data['Final classified Accuracy'].append(final_exited_accuracy)\n",
    "        summary_data['Executed layers'].append(executed_layers)\n",
    "        \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return summary_data, df"
   ],
   "id": "f6399d59eb246e40",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T21:46:50.551871Z",
     "start_time": "2024-09-26T21:46:50.548343Z"
    }
   },
   "cell_type": "code",
   "source": "thresholds = [round(x * 0.01 + 0.26, 2) for x in range(26)]",
   "id": "a4eade31aa63223",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T21:46:52.468772Z",
     "start_time": "2024-09-26T21:46:52.268817Z"
    }
   },
   "cell_type": "code",
   "source": "summary, table = explain_evaluation(dataloader=validation_dataloader, parameters=weights, prob=0.005, threshold=thresholds)",
   "id": "f0425e83bb74b17f",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "dac607ca59d1b701",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
